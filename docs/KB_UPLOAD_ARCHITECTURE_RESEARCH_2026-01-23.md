# Knowledge Base Upload Architecture Research

**Date:** 2026-01-23
**Purpose:** Comprehensive analysis of existing KB upload implementation to inform Phase 6 project-scoped document upload feature
**Status:** Complete
**Analyst:** Codebase Analyst Agent

---

## Executive Summary

### Key Findings

The Archon knowledge base upload system provides a **production-ready, battle-tested foundation** for implementing project-scoped document uploads. The system demonstrates:

1. **Robust dual-input model** (URL crawling + file uploads) with shared progress tracking
2. **Comprehensive file format support** (PDF, DOCX, TXT, MD, HTML with intelligent text extraction)
3. **Advanced progress tracking** with never-go-backwards guarantees and polling architecture
4. **Cancellation-safe background processing** with task registry and cleanup
5. **Reusable UI patterns** (drag-and-drop, tag management, toggles, sliders)

### Recommended Approach for Project Documents

**âœ… COPY EXACTLY:**
- `AddSourceDialog.tsx` component structure (modify for project scope)
- Progress tracking architecture (`ProgressTracker` + `ProgressMapper`)
- File upload endpoint pattern (`upload_document` + `_perform_upload_with_progress`)
- Text extraction utilities (`extract_text_from_document`)
- API client patterns (`uploadDocument` with FormData)

**ğŸ”§ ADAPT FOR PROJECT SCOPING:**
- Add `project_id` parameter to all requests
- Add `is_project_private` boolean flag (default: true)
- Add "Send to KB" checkbox for immediate global promotion
- Modify database storage to use project-specific tables
- Add project-level access control checks

**â• ADD NEW FEATURES:**
- Project context awareness (current project preselected)
- "Send to KB" checkbox with confirmation modal
- Project-private vs global visibility toggle
- Integration with task linking system

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js/React)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  AddSourceDialog.tsx                                            â”‚
â”‚    â”œâ”€ Two tabs: "Crawl URL" | "Upload File"                    â”‚
â”‚    â”œâ”€ Form state management (React hooks)                       â”‚
â”‚    â”œâ”€ Drag-and-drop file input                                  â”‚
â”‚    â”œâ”€ Tag management (add/remove chips)                         â”‚
â”‚    â”œâ”€ Knowledge type selector                                   â”‚
â”‚    â”œâ”€ Extract code examples toggle                              â”‚
â”‚    â””â”€ Settings loader (/api/crawl-defaults)                     â”‚
â”‚                                                                  â”‚
â”‚  CrawlingProgress.tsx                                           â”‚
â”‚    â”œâ”€ Progress polling (1 second interval)                      â”‚
â”‚    â”œâ”€ Never-go-backwards display logic                          â”‚
â”‚    â”œâ”€ Cancel/Pause/Resume controls                              â”‚
â”‚    â””â”€ Real-time stats (pages, code examples)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND API (FastAPI)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  POST /api/documents/upload                                     â”‚
â”‚    â”œâ”€ File validation (size, type)                              â”‚
â”‚    â”œâ”€ Read file content IMMEDIATELY (avoid closed file)         â”‚
â”‚    â”œâ”€ Generate progress_id (UUID)                               â”‚
â”‚    â”œâ”€ Initialize ProgressTracker                                â”‚
â”‚    â”œâ”€ Start background task (_perform_upload_with_progress)     â”‚
â”‚    â””â”€ Register in active_crawl_tasks (for cancellation)         â”‚
â”‚                                                                  â”‚
â”‚  GET /api/progress/{progress_id}                                â”‚
â”‚    â””â”€ Return ProgressTracker state from memory                  â”‚
â”‚                                                                  â”‚
â”‚  POST /api/knowledge-items/stop/{progress_id}                   â”‚
â”‚    â””â”€ Cancel task via active_crawl_tasks registry               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 BACKGROUND PROCESSING                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  _perform_upload_with_progress()                                â”‚
â”‚    â”œâ”€ Stage 1: Extract text (15-20%)                            â”‚
â”‚    â”‚   â””â”€ extract_text_from_document()                          â”‚
â”‚    â”œâ”€ Stage 2: DocumentStorageService.upload_document (30-100%) â”‚
â”‚    â”‚   â”œâ”€ Text chunking                                         â”‚
â”‚    â”‚   â”œâ”€ Embedding generation                                  â”‚
â”‚    â”‚   â”œâ”€ Code extraction (if enabled)                          â”‚
â”‚    â”‚   â””â”€ Database storage                                      â”‚
â”‚    â””â”€ Progress callbacks via ProgressMapper                     â”‚
â”‚                                                                  â”‚
â”‚  ProgressMapper                                                 â”‚
â”‚    â”œâ”€ Maps stage progress (0-100%) to overall (0-100%)          â”‚
â”‚    â”œâ”€ Stage ranges: processing(15-20), storing(30-100), etc.    â”‚
â”‚    â””â”€ Prevents progress from going backwards                    â”‚
â”‚                                                                  â”‚
â”‚  ProgressTracker                                                â”‚
â”‚    â”œâ”€ In-memory state storage (_progress_states dict)           â”‚
â”‚    â”œâ”€ Status: initializing â†’ processing â†’ storing â†’ completed   â”‚
â”‚    â”œâ”€ Never-go-backwards logic                                  â”‚
â”‚    â””â”€ Auto-cleanup after 30s delay                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. Frontend Architecture

### 1.1 Component Structure: `AddSourceDialog.tsx`

**File:** `archon-ui-nextjs/src/components/KnowledgeBase/AddSourceDialog.tsx`
**Lines:** 598 total
**Purpose:** Modal dialog for adding knowledge sources via URL crawl or file upload

#### Component Props

```typescript
interface AddSourceDialogProps {
  isOpen: boolean;
  onClose: () => void;
  onCrawl: (data: CrawlRequest) => Promise<void>;
  onUpload: (file: File, metadata: UploadMetadata) => Promise<void>;
}
```

**Pattern:** Parent component handles API calls, child handles UI state.

#### State Management (React Hooks)

```typescript
// Tab state
const [activeTab, setActiveTab] = useState<"crawl" | "upload">("crawl");

// Crawl form state
const [crawlUrl, setCrawlUrl] = useState("");
const [crawlType, setCrawlType] = useState<"technical" | "business">("technical");
const [crawlTags, setCrawlTags] = useState<string[]>([]);
const [crawlTagInput, setCrawlTagInput] = useState("");

// Upload form state
const [selectedFile, setSelectedFile] = useState<File | null>(null);
const [uploadType, setUploadType] = useState<"technical" | "business">("technical");
const [uploadTags, setUploadTags] = useState<string[]>([]);
const [uploadTagInput, setUploadTagInput] = useState("");

// Shared state
const [isSubmitting, setIsSubmitting] = useState(false);
const [error, setError] = useState<string | null>(null);

// Crawl settings (loaded from API)
const [crawlDepth, setCrawlDepth] = useState(3);
const [extractCodeExamples, setExtractCodeExamples] = useState(true);
const [isLoadingDefaults, setIsLoadingDefaults] = useState(false);
```

**Key Pattern:** Separate state for each tab, shared submission state.

#### Settings Loading (useEffect)

```typescript
useEffect(() => {
  if (isOpen) {
    setIsLoadingDefaults(true);
    fetch("/api/crawl-defaults")
      .then((res) => {
        if (!res.ok) throw new Error("Failed to load settings");
        return res.json();
      })
      .then((defaults: CrawlDefaults) => {
        setCrawlDepth(defaults.max_depth || 3);
        setCrawlType(defaults.crawl_type || "technical");
        setExtractCodeExamples(defaults.extract_code_examples ?? true);
      })
      .catch((err) => {
        console.error("Failed to load crawl defaults:", err);
        // Use sensible defaults on error
        setCrawlDepth(3);
        setExtractCodeExamples(true);
      })
      .finally(() => setIsLoadingDefaults(false));
  }
}, [isOpen]);
```

**API Endpoint:** `GET /api/crawl-defaults` (returns user-configured defaults from settings page)

**Response Format:**
```typescript
interface CrawlDefaults {
  max_depth: number;
  crawl_type: "technical" | "business";
  extract_code_examples: boolean;
}
```

### 1.2 Drag-and-Drop File Input (Lines 418-469)

**Visual States:**
- Empty: Gray dashed border with upload icon
- File selected: Purple solid border with file details
- Disabled: Grayed out with cursor-not-allowed

```tsx
{/* File Input */}
<div className="mb-4">
  <label
    htmlFor="file"
    className="mb-2 block text-sm font-medium text-gray-700 dark:text-gray-300"
  >
    Document File <span className="text-red-500">*</span>
  </label>
  <div className="relative">
    <input
      type="file"
      id="file"
      accept=".txt,.md,.pdf,.doc,.docx,.html,.htm"
      onChange={(e) => setSelectedFile(e.target.files?.[0] || null)}
      disabled={isSubmitting}
      className="absolute inset-0 z-10 h-full w-full cursor-pointer opacity-0 disabled:cursor-not-allowed"
    />
    <div
      className={`flex h-20 flex-col items-center justify-center gap-2 rounded-xl border-2 border-dashed p-4 text-center transition-all ${
        selectedFile
          ? "border-purple-400 bg-purple-50 dark:border-purple-500 dark:bg-purple-900/20"
          : "border-gray-300 bg-gray-50 hover:border-purple-400 dark:border-gray-600 dark:bg-gray-700/50"
      } ${isSubmitting ? "cursor-not-allowed opacity-50" : ""}`}
    >
      <HiUpload
        className={`h-6 w-6 ${
          selectedFile ? "text-purple-500" : "text-gray-400 dark:text-gray-500"
        }`}
      />
      <div className="text-sm">
        {selectedFile ? (
          <div className="space-y-1">
            <p className="font-medium text-purple-700 dark:text-purple-400">
              {selectedFile.name}
            </p>
            <p className="text-xs text-purple-600 dark:text-purple-400">
              {Math.round(selectedFile.size / 1024)} KB
            </p>
          </div>
        ) : (
          <div className="space-y-1">
            <p className="font-medium text-gray-700 dark:text-gray-300">
              Click to browse or drag & drop
            </p>
            <p className="text-xs text-gray-500 dark:text-gray-400">
              PDF, DOC, DOCX, TXT, MD files supported
            </p>
          </div>
        )}
      </div>
    </div>
  </div>
</div>
```

**Key Patterns:**
1. **Invisible file input overlay** - Full coverage with `absolute inset-0 opacity-0`
2. **Visual feedback layer** - Shows selected file info or upload prompt
3. **File size display** - `Math.round(file.size / 1024)` KB
4. **Accepted formats** - `.txt,.md,.pdf,.doc,.docx,.html,.htm`
5. **Conditional styling** - Purple theme when file selected, gray when empty

### 1.3 Tag Management (Lines 280-330)

**Pattern:** Input field + "Add" button â†’ Tag chips with remove buttons

```tsx
{/* Tags Input */}
<div className="mb-4">
  <label
    htmlFor="crawl_tags"
    className="mb-2 block text-sm font-medium text-gray-700 dark:text-gray-300"
  >
    Tags
  </label>
  <div className="flex gap-2">
    <input
      type="text"
      id="crawl_tags"
      value={crawlTagInput}
      onChange={(e) => setCrawlTagInput(e.target.value)}
      onKeyPress={(e) => handleKeyPress(e, handleAddCrawlTag)}
      placeholder="Press Enter or comma to add tags"
      className="flex-1 rounded-lg border border-gray-300 bg-white px-4 py-2 text-gray-900 focus:border-cyan-500 focus:ring-cyan-500 dark:border-gray-600 dark:bg-gray-700 dark:text-white"
      disabled={isSubmitting}
    />
    <button
      type="button"
      onClick={handleAddCrawlTag}
      className="rounded-lg bg-gray-100 px-4 py-2 text-sm font-medium text-gray-700 hover:bg-gray-200 dark:bg-gray-700 dark:text-gray-300 dark:hover:bg-gray-600"
      disabled={isSubmitting}
    >
      Add
    </button>
  </div>

  {/* Tags Display */}
  {crawlTags.length > 0 && (
    <div className="mt-2 flex flex-wrap gap-2">
      {crawlTags.map((tag) => (
        <span
          key={tag}
          className="inline-flex items-center gap-2 rounded-full bg-cyan-100 px-3 py-1 text-sm text-cyan-700 dark:bg-cyan-900/30 dark:text-cyan-400"
        >
          {tag}
          <button
            type="button"
            onClick={() => handleRemoveCrawlTag(tag)}
            className="text-cyan-600 hover:text-cyan-800 dark:hover:text-cyan-300"
            disabled={isSubmitting}
          >
            <HiX className="h-3 w-3" />
          </button>
        </span>
      ))}
    </div>
  )}
</div>
```

**Tag Management Functions:**

```typescript
const handleAddCrawlTag = () => {
  const tag = crawlTagInput.trim();
  if (tag && !crawlTags.includes(tag)) {
    setCrawlTags([...crawlTags, tag]);
    setCrawlTagInput("");
  }
};

const handleRemoveCrawlTag = (tagToRemove: string) => {
  setCrawlTags(crawlTags.filter((tag) => tag !== tagToRemove));
};

const handleKeyPress = (e: React.KeyboardEvent<HTMLInputElement>, handler: () => void) => {
  if (e.key === "Enter") {
    e.preventDefault();
    handler();
  }
};
```

**Key Features:**
- Duplicate prevention (`!crawlTags.includes(tag)`)
- Enter key support (`handleKeyPress`)
- Trim whitespace (`tag.trim()`)
- Chip-style display with remove X button
- Color-coded by tab (cyan for crawl, purple for upload)

### 1.4 Knowledge Type Selector (Lines 258-278)

```tsx
{/* Knowledge Type */}
<div className="mb-4">
  <label
    htmlFor="crawl_knowledge_type"
    className="mb-2 block text-sm font-medium text-gray-700 dark:text-gray-300"
  >
    Knowledge Type
  </label>
  <select
    id="crawl_knowledge_type"
    value={crawlType}
    onChange={(e) => setCrawlType(e.target.value as "technical" | "business")}
    className="w-full rounded-lg border border-gray-300 bg-white px-4 py-2 text-gray-900 focus:border-cyan-500 focus:ring-cyan-500 dark:border-gray-600 dark:bg-gray-700 dark:text-white"
    disabled={isSubmitting}
  >
    <option value="technical">Technical</option>
    <option value="business">Business</option>
  </select>
  <p className="mt-1 text-xs text-gray-500 dark:text-gray-400">
    Code, APIs, dev docs
  </p>
</div>
```

**Values:**
- `technical` - Code, APIs, development docs
- `business` - Guides, policies, general documentation

### 1.5 Extract Code Examples Toggle (Lines 363-389)

**Custom toggle switch implementation** (no external library):

```tsx
{/* Extract Code Examples Toggle */}
<div className="mb-4">
  <label className="flex cursor-pointer items-center justify-between">
    <span className="text-sm font-medium text-gray-700 dark:text-gray-300">
      Extract Code Examples
    </span>
    <button
      type="button"
      onClick={() => setExtractCodeExamples(!extractCodeExamples)}
      disabled={isSubmitting}
      className={`relative h-6 w-11 rounded-full transition-colors ${
        extractCodeExamples
          ? "bg-cyan-500"
          : "bg-gray-300 dark:bg-gray-600"
      }`}
    >
      <span
        className={`absolute left-0.5 top-0.5 h-5 w-5 rounded-full bg-white shadow transition-transform ${
          extractCodeExamples ? "translate-x-5" : "translate-x-0"
        }`}
      />
    </button>
  </label>
  <p className="mt-1 text-xs text-gray-500 dark:text-gray-400">
    Automatically extract and index code snippets from crawled pages
  </p>
</div>
```

**Key CSS Classes:**
- `translate-x-5` - Moves toggle circle right when enabled
- `translate-x-0` - Default position when disabled
- `transition-transform` - Smooth sliding animation
- Color changes: cyan (on) vs gray (off)

### 1.6 Max Depth Slider (Lines 340-361)

**Range slider with visual feedback:**

```tsx
{/* Max Depth Slider */}
<div className="mb-4">
  <label className="mb-2 flex items-center justify-between text-sm font-medium text-gray-700 dark:text-gray-300">
    <span>Max Crawl Depth</span>
    <span className="rounded bg-cyan-100 px-2 py-0.5 text-cyan-700 dark:bg-cyan-900/30 dark:text-cyan-400">
      {crawlDepth}
    </span>
  </label>
  <input
    type="range"
    min={1}
    max={5}
    value={crawlDepth}
    onChange={(e) => setCrawlDepth(Number(e.target.value))}
    disabled={isSubmitting}
    className="h-2 w-full cursor-pointer appearance-none rounded-lg bg-gray-200 accent-cyan-500 dark:bg-gray-700"
  />
  <div className="mt-1 flex justify-between text-xs text-gray-500 dark:text-gray-400">
    <span>1 (shallow)</span>
    <span>5 (deep)</span>
  </div>
</div>
```

**Value Display:** Badge shows current value dynamically

### 1.7 Submit Button States (Lines 403-409)

```tsx
<button
  type="submit"
  disabled={isSubmitting || !crawlUrl}
  className="rounded-lg bg-cyan-600 px-4 py-2 text-sm font-medium text-white hover:bg-cyan-700 disabled:cursor-not-allowed disabled:opacity-50"
>
  {isSubmitting ? "Starting..." : "Start Crawling"}
</button>
```

**States:**
- Default: "Start Crawling" / "Upload Document"
- Submitting: "Starting..." / "Uploading..."
- Disabled when: `isSubmitting || !selectedFile || !crawlUrl`

### 1.8 Form Submission Handlers

**Upload Handler (Lines 118-141):**

```typescript
const handleUploadSubmit = async (e: React.FormEvent) => {
  e.preventDefault();
  setError(null);

  if (!selectedFile) {
    setError("Please select a file to upload");
    return;
  }

  setIsSubmitting(true);
  try {
    await onUpload(selectedFile, {
      knowledge_type: uploadType,
      tags: uploadTags,
      extract_code_examples: extractCodeExamples,
    });
    resetForm();
    onClose();
  } catch (err) {
    setError(err instanceof Error ? err.message : "Failed to upload document");
  } finally {
    setIsSubmitting(false);
  }
};
```

**Data Flow:**
1. Validate file selected
2. Call parent's `onUpload(file, metadata)`
3. Reset form on success
4. Close dialog
5. Capture errors and display

---

## 2. Backend Architecture

### 2.1 Upload Endpoint: `/api/documents/upload`

**File:** `python/src/server/api_routes/knowledge_api.py`
**Lines:** 1165-1243
**Method:** POST with multipart/form-data

#### Endpoint Signature

```python
@router.post("/documents/upload")
async def upload_document(
    file: UploadFile = File(...),
    tags: str | None = Form(None),
    knowledge_type: str = Form("technical"),
    extract_code_examples: bool = Form(True),
):
    """Upload and process a document with progress tracking."""
```

**Parameters:**
- `file` - UploadFile object (FastAPI)
- `tags` - JSON string of tag array (parsed later)
- `knowledge_type` - "technical" or "business" (default: "technical")
- `extract_code_examples` - Boolean (default: True)

#### Critical Pattern: Read File Immediately

```python
# Read file content immediately to avoid closed file issues
file_content = await file.read()
file_metadata = {
    "filename": file.filename,
    "content_type": file.content_type,
    "size": len(file_content),
}
```

**Why this matters:** FastAPI's `UploadFile` is a SpooledTemporaryFile that can be closed by the time the background task runs. Reading immediately ensures data is available.

#### API Key Validation (Lines 1174-1179)

```python
# Validate API key before starting expensive upload operation
logger.info("ğŸ” About to validate API key for upload...")
provider_config = await credential_service.get_active_provider("embedding")
provider = provider_config.get("provider", "openai")
await _validate_provider_api_key(provider)
logger.info("âœ… API key validation completed successfully for upload")
```

**Purpose:** Fail fast before expensive operations (text extraction, embedding generation)

#### Tag Parsing (Lines 1190-1201)

```python
# Parse tags
try:
    tag_list = json.loads(tags) if tags else []
    if tag_list is None:
        tag_list = []
    # Validate tags is a list of strings
    if not isinstance(tag_list, list):
        raise HTTPException(status_code=422, detail={"error": "tags must be a JSON array of strings"})
    if not all(isinstance(tag, str) for tag in tag_list):
        raise HTTPException(status_code=422, detail={"error": "tags must be a JSON array of strings"})
except json.JSONDecodeError as ex:
    raise HTTPException(status_code=422, detail={"error": f"Invalid tags JSON: {str(ex)}"})
```

**Validation:**
- Must be valid JSON array
- All elements must be strings
- Returns empty array if missing or null

#### Progress Tracker Initialization (Lines 1212-1219)

```python
# Initialize progress tracker IMMEDIATELY so it's available for polling
from ..utils.progress.progress_tracker import ProgressTracker
tracker = ProgressTracker(progress_id, operation_type="upload")
await tracker.start({
    "filename": file.filename,
    "status": "initializing",
    "progress": 0,
    "log": f"Starting upload for {file.filename}"
})
```

**Critical:** Tracker is initialized **before** background task starts, so clients can poll immediately.

#### Background Task Pattern (Lines 1222-1228)

```python
# Start background task for processing with file content and metadata
upload_task = asyncio.create_task(
    _perform_upload_with_progress(
        progress_id, file_content, file_metadata, tag_list, knowledge_type, extract_code_examples, tracker
    )
)
# Track the task for cancellation support
active_crawl_tasks[progress_id] = upload_task
```

**Task Registry:** `active_crawl_tasks` (global dict) maps `progress_id` â†’ `asyncio.Task` for cancellation.

#### Response Format (Lines 1232-1237)

```python
return {
    "success": True,
    "progressId": progress_id,
    "message": "Document upload started",
    "filename": file.filename,
}
```

**Frontend uses `progressId` to poll `/api/progress/{progressId}`**

### 2.2 Background Processing: `_perform_upload_with_progress`

**File:** `python/src/server/api_routes/knowledge_api.py`
**Lines:** 1246-1365
**Purpose:** Process uploaded file with progress tracking

#### Function Signature

```python
async def _perform_upload_with_progress(
    progress_id: str,
    file_content: bytes,
    file_metadata: dict,
    tag_list: list[str],
    knowledge_type: str,
    extract_code_examples: bool,
    tracker: "ProgressTracker",
):
    """Perform document upload with progress tracking using service layer."""
```

#### Stage 1: Text Extraction (Lines 1277-1299)

```python
# Extract text from document with progress - use mapper for consistent progress
mapped_progress = progress_mapper.map_progress("processing", 50)
await tracker.update(
    status="processing",
    progress=mapped_progress,
    log=f"Extracting text from {filename}"
)

try:
    extracted_text = extract_text_from_document(file_content, filename, content_type)
    safe_logfire_info(
        f"Document text extracted | filename={filename} | extracted_length={len(extracted_text)} | content_type={content_type}"
    )
except ValueError as ex:
    # ValueError indicates unsupported format or empty file - user error
    logger.warning(f"Document validation failed: {filename} - {str(ex)}")
    await tracker.error(str(ex))
    return
except Exception as ex:
    # Other exceptions are system errors - log with full traceback
    logger.error(f"Failed to extract text from document: {filename}", exc_info=True)
    await tracker.error(f"Failed to extract text from document: {str(ex)}")
    return
```

**Error Handling:**
- `ValueError` - User error (unsupported format, empty file)
- Other exceptions - System error (full traceback logged)

#### Stage 2: Document Storage Service (Lines 1301-1335)

```python
# Use DocumentStorageService to handle the upload
doc_storage_service = DocumentStorageService(get_supabase_client())

# Generate source_id from filename with UUID to prevent collisions
source_id = f"file_{filename.replace(' ', '_').replace('.', '_')}_{uuid.uuid4().hex[:8]}"

# Create progress callback for tracking document processing
async def document_progress_callback(
    message: str, percentage: int, batch_info: dict = None
):
    """Progress callback for tracking document processing"""
    # Map the document storage progress to overall progress range
    # Use "storing" stage for uploads (30-100%), not "document_storage" (25-40%)
    mapped_percentage = progress_mapper.map_progress("storing", percentage)

    await tracker.update(
        status="storing",
        progress=mapped_percentage,
        log=message,
        currentUrl=f"file://{filename}",
        **(batch_info or {})
    )

# Call the service's upload_document method
success, result = await doc_storage_service.upload_document(
    file_content=extracted_text,
    filename=filename,
    source_id=source_id,
    knowledge_type=knowledge_type,
    tags=tag_list,
    extract_code_examples=extract_code_examples,
    progress_callback=document_progress_callback,
    cancellation_check=check_upload_cancellation,
)
```

**Progress Callback Pattern:**
- Service calls `progress_callback(message, percentage, batch_info)`
- Callback maps stage progress â†’ overall progress via `ProgressMapper`
- Updates `ProgressTracker` with mapped progress

#### Stage 3: Completion (Lines 1337-1350)

```python
if success:
    # Complete the upload with 100% progress
    await tracker.complete({
        "log": "Document uploaded successfully!",
        "chunks_stored": result.get("chunks_stored"),
        "code_examples_stored": result.get("code_examples_stored", 0),
        "sourceId": result.get("source_id"),
    })
    safe_logfire_info(
        f"Document uploaded successfully | progress_id={progress_id} | source_id={result.get('source_id')} | chunks_stored={result.get('chunks_stored')} | code_examples_stored={result.get('code_examples_stored', 0)}"
    )
else:
    error_msg = result.get("error", "Unknown error")
    await tracker.error(error_msg)
```

#### Cancellation Check (Lines 1257-1261)

```python
def check_upload_cancellation():
    """Check if upload task has been cancelled."""
    task = active_crawl_tasks.get(progress_id)
    if task and task.cancelled():
        raise asyncio.CancelledError("Document upload was cancelled by user")
```

**Pattern:** Service layer checks cancellation before expensive operations (embedding generation, etc.)

#### Cleanup (finally block)

```python
finally:
    # Clean up task from registry when done (success or failure)
    if progress_id in active_crawl_tasks:
        del active_crawl_tasks[progress_id]
        safe_logfire_info(
            f"Cleaned up upload task from registry | progress_id={progress_id}"
        )
```

**Task Registry Cleanup:** Ensures no memory leaks

### 2.3 Text Extraction: `extract_text_from_document`

**File:** `python/src/server/utils/document_processing.py`
**Lines:** 158-222
**Purpose:** Extract text from various document formats

#### Supported Formats

```python
def extract_text_from_document(file_content: bytes, filename: str, content_type: str) -> str:
    """
    Extract text from various document formats.

    Returns:
        Extracted text content

    Raises:
        ValueError: If the file format is not supported
        Exception: If extraction fails
    """
    try:
        # PDF files
        if content_type == "application/pdf" or filename.lower().endswith(".pdf"):
            return extract_text_from_pdf(file_content)

        # Word documents
        elif content_type in [
            "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            "application/msword",
        ] or filename.lower().endswith((".docx", ".doc")):
            return extract_text_from_docx(file_content)

        # HTML files - clean tags and extract text
        elif content_type == "text/html" or filename.lower().endswith((".html", ".htm")):
            html_text = file_content.decode("utf-8", errors="ignore").strip()
            if not html_text:
                raise ValueError(f"The file {filename} appears to be empty.")
            return _clean_html_to_text(html_text)

        # Text files (markdown, txt, etc.)
        elif content_type.startswith("text/") or filename.lower().endswith((
            ".txt",
            ".md",
            ".markdown",
            ".rst",
        )):
            text = file_content.decode("utf-8", errors="ignore").strip()
            if not text:
                raise ValueError(f"The file {filename} appears to be empty.")
            return text

        else:
            raise ValueError(f"Unsupported file format: {content_type} ({filename})")

    except ValueError:
        # Re-raise ValueError with original message for unsupported formats
        raise
    except Exception as e:
        logfire.error(
            "Document text extraction failed",
            filename=filename,
            content_type=content_type,
            error=str(e),
        )
        raise Exception(f"Failed to extract text from {filename}") from e
```

**Format Detection:** Uses both `content_type` (MIME) and `filename` extension.

#### PDF Extraction (Lines 224-304)

**Libraries:**
1. **pdfplumber** (primary) - Better for complex layouts
2. **PyPDF2** (fallback) - Backup method

```python
def extract_text_from_pdf(file_content: bytes) -> str:
    """Extract text from PDF using both PyPDF2 and pdfplumber for best results."""
    if not PDFPLUMBER_AVAILABLE and not PYPDF2_AVAILABLE:
        raise Exception("No PDF processing libraries available. Please install pdfplumber and PyPDF2.")

    text_content = []

    # First try with pdfplumber (better for complex layouts)
    if PDFPLUMBER_AVAILABLE:
        try:
            with pdfplumber.open(io.BytesIO(file_content)) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            text_content.append(f"--- Page {page_num + 1} ---\n{page_text}")
                    except Exception as e:
                        logfire.warning(f"pdfplumber failed on page {page_num + 1}: {e}")
                        continue

            # If pdfplumber got good results, use them
            if text_content and len("\n".join(text_content).strip()) > 100:
                combined_text = "\n\n".join(text_content)
                return _preserve_code_blocks_across_pages(combined_text)

        except Exception as e:
            logfire.warning(f"pdfplumber extraction failed: {e}, trying PyPDF2")

    # Fallback to PyPDF2
    # ... (similar pattern)
```

**Page Markers:** `--- Page N ---` separators for multi-page PDFs

**Code Block Preservation:**
```python
def _preserve_code_blocks_across_pages(text: str) -> str:
    """
    Fix code blocks that were split across PDF page boundaries.

    PDFs often break markdown code blocks with page headers like:
    ```python
    def hello():
    --- Page 2 ---
        return "world"
    ```

    This function rejoins split code blocks by removing page separators.
    """
    import re

    page_break_in_code_pattern = r'(```\w*[^\n]*\n(?:[^`]|`(?!``))*)(\n--- Page \d+ ---\n)((?:[^`]|`(?!``))*)```'

    while True:
        matches = list(re.finditer(page_break_in_code_pattern, text, re.DOTALL))
        if not matches:
            break

        for match in reversed(matches):
            before_page_break = match.group(1)
            after_page_break = match.group(3)
            rejoined = f"{before_page_break}\n{after_page_break}```"
            text = text[:match.start()] + rejoined + text[match.end():]

    return text
```

#### HTML Cleaning (Lines 78-155)

**Purpose:** Remove HTML tags while preserving code blocks and structure

```python
def _clean_html_to_text(html_content: str) -> str:
    """
    Clean HTML tags and convert to plain text suitable for RAG.
    Preserves code blocks and important structure while removing markup.
    """
    # 1. Extract and preserve code blocks
    # 2. Remove scripts and styles
    # 3. Convert structural elements (headers, paragraphs, lists)
    # 4. Remove all remaining HTML tags
    # 5. Clean HTML entities
    # 6. Restore code blocks as ```...```
    # 7. Clean up excessive whitespace
```

**Code Block Patterns:**
```python
code_patterns = [
    r'<pre><code[^>]*>(.*?)</code></pre>',
    r'<code[^>]*>(.*?)</code>',
    r'<pre[^>]*>(.*?)</pre>',
]
```

#### DOCX Extraction (Lines 307-344)

```python
def extract_text_from_docx(file_content: bytes) -> str:
    """Extract text from Word documents (.docx)."""
    if not DOCX_AVAILABLE:
        raise Exception("python-docx library not available. Please install python-docx.")

    try:
        doc = DocxDocument(io.BytesIO(file_content))
        text_content = []

        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                text_content.append(paragraph.text)

        # Also extract text from tables
        for table in doc.tables:
            for row in table.rows:
                row_text = []
                for cell in row.cells:
                    if cell.text.strip():
                        row_text.append(cell.text.strip())
                if row_text:
                    text_content.append(" | ".join(row_text))

        if not text_content:
            raise ValueError("No text content found in document")

        return "\n\n".join(text_content)

    except Exception as e:
        raise Exception("Failed to extract text from Word document") from e
```

**Table Handling:** Extracts text from both paragraphs and tables (pipe-delimited)

---

## 3. Progress Tracking Architecture

### 3.1 ProgressTracker Class

**File:** `python/src/server/utils/progress/progress_tracker.py`
**Lines:** 1-369
**Purpose:** In-memory progress state storage with HTTP polling access

#### Class-Level Storage

```python
class ProgressTracker:
    """
    Utility class for tracking progress updates in memory.
    State can be accessed via HTTP polling endpoints.
    """

    # Class-level storage for all progress states
    _progress_states: dict[str, dict[str, Any]] = {}
```

**Pattern:** Single shared dictionary across all instances (class variable)

#### State Structure

```python
self.state = {
    "progress_id": progress_id,
    "type": operation_type,  # "crawl" or "upload"
    "start_time": datetime.now().isoformat(),
    "status": "initializing",
    "progress": 0,
    "logs": [],
}
```

#### Key Methods

**Start Tracking:**
```python
async def start(self, initial_data: dict[str, Any] | None = None):
    """Start progress tracking with initial data."""
    self.state["status"] = "starting"
    self.state["start_time"] = datetime.now().isoformat()

    if initial_data:
        self.state.update(initial_data)

    self._update_state()
```

**Update Progress (with never-go-backwards):**
```python
async def update(self, status: str, progress: int, log: str, **kwargs):
    """Update progress with status, progress, and log message."""
    # CRITICAL: Never allow progress to go backwards
    current_progress = self.state.get("progress", 0)
    new_progress = min(100, max(0, progress))  # Ensure 0-100

    # Only update if new progress is greater than or equal to current
    if new_progress < current_progress:
        safe_logfire_info(
            f"Progress backwards prevented: {current_progress}% -> {new_progress}% | "
            f"progress_id={self.progress_id} | status={status}"
        )
        actual_progress = current_progress
    else:
        actual_progress = new_progress

    self.state.update({
        "status": status,
        "progress": actual_progress,
        "log": log,
        "timestamp": datetime.now().isoformat(),
    })

    # Add log entry (keep last 200)
    self.state["logs"].append({
        "timestamp": datetime.now().isoformat(),
        "message": log,
        "status": status,
        "progress": actual_progress,
    })
    if len(self.state["logs"]) > 200:
        self.state["logs"] = self.state["logs"][-200:]

    # Add any additional data
    protected_fields = {"progress", "status", "log", "progress_id", "type", "start_time"}
    for key, value in kwargs.items():
        if key not in protected_fields:
            self.state[key] = value

    self._update_state()
```

**Complete:**
```python
async def complete(self, completion_data: dict[str, Any] | None = None):
    """Mark progress as completed with optional completion data."""
    self.state["status"] = "completed"
    self.state["progress"] = 100
    self.state["end_time"] = datetime.now().isoformat()

    if completion_data:
        self.state.update(completion_data)

    # Calculate duration
    if "start_time" in self.state:
        start = datetime.fromisoformat(self.state["start_time"])
        end = datetime.fromisoformat(self.state["end_time"])
        duration = (end - start).total_seconds()
        self.state["duration"] = str(duration)
        self.state["duration_formatted"] = self._format_duration(duration)

    self._update_state()

    # Schedule cleanup after delay to allow clients to see final state
    asyncio.create_task(self._delayed_cleanup(self.progress_id))
```

**Error Handling:**
```python
async def error(self, error_message: str, error_details: dict[str, Any] | None = None):
    """Mark progress as failed with error information."""
    self.state.update({
        "status": "error",
        "error": error_message,
        "error_time": datetime.now().isoformat(),
    })

    if error_details:
        self.state["error_details"] = error_details

    self._update_state()

    # Schedule cleanup after delay
    asyncio.create_task(self._delayed_cleanup(self.progress_id))
```

#### Auto-Cleanup (Lines 61-73)

```python
@classmethod
async def _delayed_cleanup(cls, progress_id: str, delay_seconds: int = 30):
    """
    Remove progress state from memory after a delay.

    This gives clients time to see the final state before cleanup.
    """
    await asyncio.sleep(delay_seconds)
    if progress_id in cls._progress_states:
        status = cls._progress_states[progress_id].get("status", "unknown")
        # Only clean up if still in terminal state (prevent cleanup of reused IDs)
        if status in ["completed", "failed", "error", "cancelled"]:
            del cls._progress_states[progress_id]
            safe_logfire_info(f"Progress state cleaned up after delay | progress_id={progress_id} | status={status}")
```

**30-second grace period** allows clients to poll final state before cleanup.

### 3.2 ProgressMapper Class

**File:** `python/src/server/services/crawling/progress_mapper.py`
**Lines:** 1-171
**Purpose:** Maps sub-task progress (0-100%) to overall progress ranges

#### Stage Ranges

```python
class ProgressMapper:
    """Maps sub-task progress to overall progress ranges"""

    # Define progress ranges for each stage
    STAGE_RANGES = {
        # Common stages
        "starting": (0, 1),
        "initializing": (0, 1),
        "error": (-1, -1),
        "cancelled": (-1, -1),
        "completed": (100, 100),

        # Crawl-specific stages
        "analyzing": (1, 3),
        "discovery": (3, 4),
        "crawling": (4, 15),
        "processing": (15, 20),
        "source_creation": (20, 25),
        "document_storage": (25, 40),
        "code_extraction": (40, 90),
        "finalization": (90, 100),

        # Upload-specific stages
        "reading": (0, 5),
        "text_extraction": (5, 10),
        "chunking": (10, 15),
        "summarizing": (25, 35),
        "storing": (35, 100),  # Upload uses wider range (35-100)
    }
```

**Upload Progress Timeline:**
- 0-10%: Text extraction
- 10-15%: Chunking
- 15-20%: Source creation
- 20-35%: Summarization
- 35-100%: Embedding generation + storage (longest operation)

#### Map Progress Method

```python
def map_progress(self, stage: str, stage_progress: float) -> int:
    """
    Map stage-specific progress to overall progress.

    Args:
        stage: The current stage name
        stage_progress: Progress within the stage (0-100)

    Returns:
        Overall progress percentage (0-100)
    """
    # Handle error and cancelled states - preserve last known progress
    if stage in ("error", "cancelled"):
        return self.last_overall_progress

    # Get stage range
    if stage not in self.STAGE_RANGES:
        return self.last_overall_progress

    start, end = self.STAGE_RANGES[stage]

    # Handle completion
    if stage in ["completed", "complete"]:
        self.last_overall_progress = 100
        return 100

    # Calculate mapped progress
    stage_progress = max(0, min(100, stage_progress))  # Clamp to 0-100
    stage_range = end - start
    mapped_progress = start + (stage_progress / 100.0) * stage_range

    # Ensure progress never goes backwards
    mapped_progress = max(self.last_overall_progress, mapped_progress)

    # Round to integer
    overall_progress = int(round(mapped_progress))

    # Update state
    self.last_overall_progress = overall_progress
    self.current_stage = stage

    return overall_progress
```

**Example:** Stage "storing" at 50% internal progress:
- Range: (35, 100)
- Calculation: 35 + (50/100) * (100-35) = 35 + 32.5 = 67.5% â†’ 68%

#### Never-Go-Backwards Guarantee

**Two layers of protection:**

1. **ProgressMapper:** `mapped_progress = max(self.last_overall_progress, mapped_progress)`
2. **ProgressTracker:** `actual_progress = max(current_progress, new_progress)`

**Example Scenario:**
- Stage 1 ends at 40%
- Stage 2 starts with 0% internal progress
- Without protection: Would jump to 20% (stage 2 start)
- With protection: Stays at 40% until stage 2 exceeds it

### 3.3 Progress Polling UI

**File:** `archon-ui-nextjs/src/components/KnowledgeBase/CrawlingProgress.tsx`
**Lines:** 1-382
**Purpose:** Real-time progress display with polling

#### Polling Implementation

```typescript
export function CrawlingProgress({ className = "" }: CrawlingProgressProps) {
  const [liveUpdates, setLiveUpdates] = useState(true);
  const { data, isLoading, isError, refetch } = useProgressList({
    enabled: liveUpdates,
    pollingInterval: 1000,  // Poll every 1 second
  });

  const operations = data?.operations || [];
  const activeOperations = operations.filter((op: Progress) =>
    !["completed", "error", "failed", "cancelled"].includes(op.status)
  );
```

**Hook:** `useProgressList` from TanStack Query with `pollingInterval: 1000ms`

#### Never-Go-Backwards Display Logic

```typescript
function OperationCard({ operation, onStop, onPause, onResume }: OperationCardProps) {
  // Never-go-backwards logic: track previous progress values
  const [prevProgress, setPrevProgress] = useState<number>(0);
  const [prevPagesCrawled, setPrevPagesCrawled] = useState<number>(0);
  const [prevCodeExamples, setPrevCodeExamples] = useState<number>(0);

  // Ensure progress only increases
  const displayProgress = Math.max(operation.progress_percentage ?? 0, prevProgress);
  const displayPagesCrawled = Math.max(operation.pages_crawled ?? 0, prevPagesCrawled);
  const displayCodeExamples = Math.max(operation.code_examples_found ?? 0, prevCodeExamples);

  // Update previous values when progress increases
  if (displayProgress > prevProgress) {
    setPrevProgress(displayProgress);
  }
  if (displayPagesCrawled > prevPagesCrawled) {
    setPrevPagesCrawled(displayPagesCrawled);
  }
  if (displayCodeExamples > prevCodeExamples) {
    setPrevCodeExamples(displayCodeExamples);
  }
```

**Three layers of never-go-backwards protection:**
1. Backend ProgressMapper
2. Backend ProgressTracker
3. Frontend display state

#### Progress Bar Rendering

```tsx
{/* Progress Bar */}
<div className="mb-3">
  <div className="mb-1 flex items-center justify-between text-sm">
    <span className="text-gray-600 dark:text-gray-400">Progress</span>
    <span className="font-medium text-cyan-600 dark:text-cyan-400">
      {displayProgress}%
    </span>
  </div>
  <div className="h-2 w-full overflow-hidden rounded-full bg-gray-200 dark:bg-gray-700">
    <div
      className="h-full rounded-full bg-cyan-500 transition-all duration-300"
      style={{ width: `${displayProgress}%` }}
    />
  </div>
</div>
```

**Animation:** `transition-all duration-300` for smooth progress bar movement

#### Status Badges

```typescript
const getStatusColor = (status: ProgressStatus) => {
  switch (status) {
    case "pending":
      return "bg-gray-100 text-gray-700 dark:bg-gray-700 dark:text-gray-300";
    case "crawling":
      return "bg-cyan-100 text-cyan-700 dark:bg-cyan-900/30 dark:text-cyan-400";
    case "processing":
    case "storing":
    case "document_storage":
      return "bg-brand-100 text-brand-700 dark:bg-brand-900/30 dark:text-brand-400";
    case "paused":
      return "bg-yellow-100 text-yellow-700 dark:bg-yellow-900/30 dark:text-yellow-400";
    case "completed":
      return "bg-green-100 text-green-700 dark:bg-green-900/30 dark:text-green-400";
    case "error":
    case "failed":
    case "cancelled":
      return "bg-red-100 text-red-700 dark:bg-red-900/30 dark:text-red-400";
    default:
      return "bg-gray-100 text-gray-700 dark:bg-gray-700 dark:text-gray-300";
  }
};
```

#### Cancel Control

```typescript
const handleStop = async (progressId: string) => {
  try {
    await progressApi.stop(progressId);
    refetch();
  } catch (error) {
    console.error("Failed to stop operation:", error);
    alert("Failed to stop operation. Please try again.");
  }
};
```

**API:** `POST /api/knowledge-items/stop/{progressId}`

---

## 4. Data Flow Diagrams

### 4.1 File Upload Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USER INTERACTION                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ User selects file via drag-and-drop or browse
   â”‚ User configures: knowledge_type, tags, extract_code_examples
   â”‚ User clicks "Upload Document"
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FRONTEND VALIDATION (AddSourceDialog.tsx)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ Check: file != null
   â”‚ Set: isSubmitting = true
   â”‚ Call: onUpload(file, metadata)
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. API CLIENT (apiClient.ts)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ Build FormData:
   â”‚   - file: File object
   â”‚   - knowledge_type: "technical" | "business"
   â”‚   - tags: JSON.stringify(string[])
   â”‚   - extract_code_examples: boolean
   â”‚
   â”‚ POST /api/documents/upload
   â”‚   Content-Type: multipart/form-data
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. BACKEND ENDPOINT (knowledge_api.py)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ Parse FormData parameters
   â”‚ Validate API key (fail fast)
   â”‚ Read file content IMMEDIATELY (avoid closed file)
   â”‚ Generate progress_id = uuid4()
   â”‚ Parse tags from JSON string
   â”‚
   â”‚ Initialize ProgressTracker (operation_type="upload")
   â”‚ Start background task: _perform_upload_with_progress()
   â”‚ Register task in active_crawl_tasks[progress_id]
   â”‚
   â”‚ Return: {success: true, progressId: "...", filename: "..."}
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. FRONTEND POLLING (CrawlingProgress.tsx)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ Start polling: GET /api/progress/{progressId}
   â”‚   Interval: 1000ms (1 second)
   â”‚   Auto-refresh: enabled
   â”‚
   â”‚ Display:
   â”‚   - Progress bar (0-100%)
   â”‚   - Status badge (processing, storing, etc.)
   â”‚   - Current operation message
   â”‚   - Cancel/Pause/Resume buttons
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. BACKGROUND PROCESSING (_perform_upload_with_progress)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”œâ”€ STAGE 1: Text Extraction (15-20%)
   â”‚    â”‚
   â”‚    â”‚ tracker.update(status="processing", progress=18%, log="Extracting...")
   â”‚    â”‚ extracted_text = extract_text_from_document(file_content, filename, content_type)
   â”‚    â”‚   â”œâ”€ PDF: pdfplumber â†’ PyPDF2 fallback
   â”‚    â”‚   â”œâ”€ DOCX: python-docx (paragraphs + tables)
   â”‚    â”‚   â”œâ”€ HTML: clean tags, preserve code blocks
   â”‚    â”‚   â””â”€ TXT/MD: decode UTF-8
   â”‚    â”‚
   â”‚    â–¼
   â”œâ”€ STAGE 2: Document Storage (30-100%)
   â”‚    â”‚
   â”‚    â”‚ source_id = f"file_{filename}_{uuid.hex[:8]}"
   â”‚    â”‚ progress_callback = lambda msg, pct: tracker.update(...)
   â”‚    â”‚
   â”‚    â”‚ doc_storage_service.upload_document(
   â”‚    â”‚   file_content=extracted_text,
   â”‚    â”‚   filename=filename,
   â”‚    â”‚   source_id=source_id,
   â”‚    â”‚   knowledge_type=knowledge_type,
   â”‚    â”‚   tags=tag_list,
   â”‚    â”‚   extract_code_examples=extract_code_examples,
   â”‚    â”‚   progress_callback=progress_callback,
   â”‚    â”‚   cancellation_check=check_upload_cancellation
   â”‚    â”‚ )
   â”‚    â”‚
   â”‚    â”‚ Service performs:
   â”‚    â”‚   â”œâ”€ Text chunking (semantic splitting)
   â”‚    â”‚   â”œâ”€ Embedding generation (OpenAI/Azure)
   â”‚    â”‚   â”œâ”€ Code extraction (if enabled)
   â”‚    â”‚   â”œâ”€ Code summarization (LLM-based)
   â”‚    â”‚   â””â”€ Database storage (archon_crawled_pages, archon_code_examples)
   â”‚    â”‚
   â”‚    â”‚ Calls progress_callback() at each step with percentage
   â”‚    â”‚
   â”‚    â–¼
   â””â”€ STAGE 3: Completion
        â”‚
        â”‚ tracker.complete({
        â”‚   "log": "Document uploaded successfully!",
        â”‚   "chunks_stored": 42,
        â”‚   "code_examples_stored": 7,
        â”‚   "sourceId": "file_example_pdf_a1b2c3d4"
        â”‚ })
        â”‚
        â”‚ Cleanup: del active_crawl_tasks[progress_id]
        â”‚ Auto-cleanup state after 30s delay
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. COMPLETION                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ Frontend detects status="completed"
   â”‚ Stop polling
   â”‚ Show success notification
   â”‚ Refresh knowledge sources list
   â”‚
   â–¼
```

### 4.2 URL Crawl Flow (for comparison)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER INPUT: URL + settings                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST /api/knowledge-items/crawl                             â”‚
â”‚   {url, knowledge_type, tags, max_depth, extract_code_examples} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CrawlingService.crawl_and_index()                           â”‚
â”‚   â”œâ”€ Stage 1: Analyzing URL (1-3%)                          â”‚
â”‚   â”œâ”€ Stage 2: Crawling (4-15%)                              â”‚
â”‚   â”‚    â””â”€ Queue-based recursive crawling                    â”‚
â”‚   â”œâ”€ Stage 3: Processing (15-20%)                           â”‚
â”‚   â”œâ”€ Stage 4: Document Storage (25-40%)                     â”‚
â”‚   â””â”€ Stage 5: Code Extraction (40-90%)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Progress polling: same as upload                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Progress Tracking Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SERVICE LAYER (DocumentStorageService)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ At key milestones:
   â”‚   progress_callback(message="Generating embeddings...", percentage=45, batch_info={...})
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROGRESS CALLBACK (in _perform_upload_with_progress)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ mapped_percentage = progress_mapper.map_progress("storing", 45)
   â”‚   â”œâ”€ Stage range: (35, 100)
   â”‚   â”œâ”€ Calculation: 35 + (45/100) * 65 = 64.25% â†’ 64%
   â”‚   â””â”€ Never-go-backwards check: max(last_progress, 64%)
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROGRESS TRACKER                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ tracker.update(
   â”‚   status="storing",
   â”‚   progress=64,  # Mapped overall progress
   â”‚   log="Generating embeddings...",
   â”‚   currentUrl="file://example.pdf",
   â”‚   **batch_info
   â”‚ )
   â”‚
   â”‚ â”œâ”€ Never-go-backwards check: max(current_progress, 64)
   â”‚ â”œâ”€ Update state dict: ProgressTracker._progress_states[progress_id]
   â”‚ â”œâ”€ Append log entry (keep last 200)
   â”‚ â””â”€ Log to console/logfire
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP POLLING ENDPOINT                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ GET /api/progress/{progress_id}
   â”‚
   â”‚ state = ProgressTracker.get_progress(progress_id)
   â”‚ return {
   â”‚   "operation_id": progress_id,
   â”‚   "operation_type": "upload",
   â”‚   "status": "storing",
   â”‚   "progress": 64,
   â”‚   "message": "Generating embeddings...",
   â”‚   "started_at": "2026-01-23T10:00:00",
   â”‚   ...
   â”‚ }
   â”‚
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FRONTEND (CrawlingProgress.tsx)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ useProgressList() hook (TanStack Query)
   â”‚   â”œâ”€ Polls every 1000ms
   â”‚   â”œâ”€ Transforms API response to frontend format
   â”‚   â””â”€ Updates React state
   â”‚
   â”‚ OperationCard component:
   â”‚   â”œâ”€ Never-go-backwards display logic (3rd layer)
   â”‚   â”œâ”€ Renders progress bar: width={displayProgress}%
   â”‚   â”œâ”€ Shows status badge
   â”‚   â””â”€ Displays stats (pages, code examples)
   â”‚
   â–¼
```

---

## 5. Reusable Code Patterns

### 5.1 Drag-and-Drop File Input (Copy This)

```tsx
{/* File Input with Drag-and-Drop Overlay */}
<div className="relative">
  {/* Invisible file input - full coverage */}
  <input
    type="file"
    id="file"
    accept=".txt,.md,.pdf,.doc,.docx,.html,.htm"
    onChange={(e) => setSelectedFile(e.target.files?.[0] || null)}
    disabled={isSubmitting}
    className="absolute inset-0 z-10 h-full w-full cursor-pointer opacity-0 disabled:cursor-not-allowed"
  />

  {/* Visual feedback layer */}
  <div
    className={`flex h-20 flex-col items-center justify-center gap-2 rounded-xl border-2 border-dashed p-4 text-center transition-all ${
      selectedFile
        ? "border-purple-400 bg-purple-50 dark:border-purple-500 dark:bg-purple-900/20"
        : "border-gray-300 bg-gray-50 hover:border-purple-400 dark:border-gray-600 dark:bg-gray-700/50"
    } ${isSubmitting ? "cursor-not-allowed opacity-50" : ""}`}
  >
    <HiUpload
      className={`h-6 w-6 ${
        selectedFile ? "text-purple-500" : "text-gray-400 dark:text-gray-500"
      }`}
    />
    <div className="text-sm">
      {selectedFile ? (
        <div className="space-y-1">
          <p className="font-medium text-purple-700 dark:text-purple-400">
            {selectedFile.name}
          </p>
          <p className="text-xs text-purple-600 dark:text-purple-400">
            {Math.round(selectedFile.size / 1024)} KB
          </p>
        </div>
      ) : (
        <div className="space-y-1">
          <p className="font-medium text-gray-700 dark:text-gray-300">
            Click to browse or drag & drop
          </p>
          <p className="text-xs text-gray-500 dark:text-gray-400">
            PDF, DOC, DOCX, TXT, MD files supported
          </p>
        </div>
      )}
    </div>
  </div>
</div>
```

**Adaptation for Project Documents:**
- Change border color from purple to project theme color
- Add file type restrictions if needed (e.g., only PDF for contracts)
- Add file size limit indicator

### 5.2 Tag Management (Copy This)

```tsx
{/* Tag Input with Add/Remove */}
<div className="mb-4">
  <label className="mb-2 block text-sm font-medium text-gray-700 dark:text-gray-300">
    Tags
  </label>
  <div className="flex gap-2">
    <input
      type="text"
      value={tagInput}
      onChange={(e) => setTagInput(e.target.value)}
      onKeyPress={(e) => {
        if (e.key === "Enter") {
          e.preventDefault();
          handleAddTag();
        }
      }}
      placeholder="Press Enter to add tags"
      className="flex-1 rounded-lg border border-gray-300 bg-white px-4 py-2 text-gray-900 focus:border-cyan-500 focus:ring-cyan-500 dark:border-gray-600 dark:bg-gray-700 dark:text-white"
      disabled={isSubmitting}
    />
    <button
      type="button"
      onClick={handleAddTag}
      className="rounded-lg bg-gray-100 px-4 py-2 text-sm font-medium text-gray-700 hover:bg-gray-200 dark:bg-gray-700 dark:text-gray-300 dark:hover:bg-gray-600"
      disabled={isSubmitting}
    >
      Add
    </button>
  </div>

  {/* Tag Chips Display */}
  {tags.length > 0 && (
    <div className="mt-2 flex flex-wrap gap-2">
      {tags.map((tag) => (
        <span
          key={tag}
          className="inline-flex items-center gap-2 rounded-full bg-cyan-100 px-3 py-1 text-sm text-cyan-700 dark:bg-cyan-900/30 dark:text-cyan-400"
        >
          {tag}
          <button
            type="button"
            onClick={() => handleRemoveTag(tag)}
            className="text-cyan-600 hover:text-cyan-800 dark:hover:text-cyan-300"
            disabled={isSubmitting}
          >
            <HiX className="h-3 w-3" />
          </button>
        </span>
      ))}
    </div>
  )}
</div>

{/* Handler Functions */}
<script>
const handleAddTag = () => {
  const tag = tagInput.trim();
  if (tag && !tags.includes(tag)) {
    setTags([...tags, tag]);
    setTagInput("");
  }
};

const handleRemoveTag = (tagToRemove: string) => {
  setTags(tags.filter((tag) => tag !== tagToRemove));
};
</script>
```

**Adaptation for Project Documents:**
- Preload project-specific tag suggestions
- Add tag validation (max length, allowed characters)
- Integrate with project tag taxonomy

### 5.3 Custom Toggle Switch (Copy This)

```tsx
{/* Toggle Switch */}
<div className="mb-4">
  <label className="flex cursor-pointer items-center justify-between">
    <span className="text-sm font-medium text-gray-700 dark:text-gray-300">
      Extract Code Examples
    </span>
    <button
      type="button"
      onClick={() => setExtractCodeExamples(!extractCodeExamples)}
      disabled={isSubmitting}
      className={`relative h-6 w-11 rounded-full transition-colors ${
        extractCodeExamples
          ? "bg-cyan-500"
          : "bg-gray-300 dark:bg-gray-600"
      }`}
    >
      <span
        className={`absolute left-0.5 top-0.5 h-5 w-5 rounded-full bg-white shadow transition-transform ${
          extractCodeExamples ? "translate-x-5" : "translate-x-0"
        }`}
      />
    </button>
  </label>
  <p className="mt-1 text-xs text-gray-500 dark:text-gray-400">
    Automatically extract and index code snippets
  </p>
</div>
```

**Adaptation for "Send to KB" Checkbox:**

```tsx
{/* Send to KB Checkbox */}
<div className="mb-4">
  <label className="flex cursor-pointer items-center justify-between">
    <div className="flex-1">
      <span className="text-sm font-medium text-gray-700 dark:text-gray-300">
        Send to Knowledge Base
      </span>
      <p className="mt-1 text-xs text-gray-500 dark:text-gray-400">
        Make this document immediately available in the global knowledge base
      </p>
    </div>
    <button
      type="button"
      onClick={() => setSendToKB(!sendToKB)}
      disabled={isSubmitting}
      className={`relative h-6 w-11 rounded-full transition-colors ${
        sendToKB
          ? "bg-green-500"
          : "bg-gray-300 dark:bg-gray-600"
      }`}
    >
      <span
        className={`absolute left-0.5 top-0.5 h-5 w-5 rounded-full bg-white shadow transition-transform ${
          sendToKB ? "translate-x-5" : "translate-x-0"
        }`}
      />
    </button>
  </label>
</div>
```

### 5.4 Backend Upload Endpoint (Adapt This)

```python
@router.post("/api/projects/{project_id}/documents/upload")
async def upload_project_document(
    project_id: str,
    file: UploadFile = File(...),
    tags: str | None = Form(None),
    knowledge_type: str = Form("technical"),
    extract_code_examples: bool = Form(True),
    is_project_private: bool = Form(True),  # NEW: Project-scoped
    send_to_kb: bool = Form(False),  # NEW: Immediate KB promotion
):
    """Upload document to project with optional KB promotion."""

    # 1. Validate project access
    project = await project_service.get_project(project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")

    # 2. Read file immediately (avoid closed file)
    file_content = await file.read()
    file_metadata = {
        "filename": file.filename,
        "content_type": file.content_type,
        "size": len(file_content),
        "project_id": project_id,  # NEW: Track project ownership
        "is_project_private": is_project_private,  # NEW: Visibility flag
    }

    # 3. Parse tags
    tag_list = json.loads(tags) if tags else []

    # 4. Generate progress_id
    progress_id = str(uuid.uuid4())

    # 5. Initialize progress tracker
    tracker = ProgressTracker(progress_id, operation_type="upload")
    await tracker.start({
        "filename": file.filename,
        "project_id": project_id,
        "is_project_private": is_project_private,
        "status": "initializing",
        "progress": 0,
        "log": f"Starting upload for {file.filename}"
    })

    # 6. Start background task
    upload_task = asyncio.create_task(
        _perform_project_upload_with_progress(
            progress_id, project_id, file_content, file_metadata,
            tag_list, knowledge_type, extract_code_examples,
            is_project_private, send_to_kb, tracker
        )
    )

    # 7. Register task for cancellation
    active_crawl_tasks[progress_id] = upload_task

    # 8. Return response
    return {
        "success": True,
        "progressId": progress_id,
        "message": "Project document upload started",
        "filename": file.filename,
        "project_id": project_id,
    }
```

**Key Additions:**
- `project_id` path parameter (validates project exists)
- `is_project_private` form field (default: True)
- `send_to_kb` form field (default: False)
- Project ownership tracking in metadata

### 5.5 Backend Background Processing (Adapt This)

```python
async def _perform_project_upload_with_progress(
    progress_id: str,
    project_id: str,  # NEW
    file_content: bytes,
    file_metadata: dict,
    tag_list: list[str],
    knowledge_type: str,
    extract_code_examples: bool,
    is_project_private: bool,  # NEW
    send_to_kb: bool,  # NEW
    tracker: "ProgressTracker",
):
    """Process project document upload with optional KB promotion."""

    try:
        filename = file_metadata["filename"]
        content_type = file_metadata["content_type"]

        # Stage 1: Extract text (15-20%)
        mapped_progress = progress_mapper.map_progress("processing", 50)
        await tracker.update(
            status="processing",
            progress=mapped_progress,
            log=f"Extracting text from {filename}"
        )

        extracted_text = extract_text_from_document(file_content, filename, content_type)

        # Stage 2: Store in project-specific table (30-100%)
        project_doc_service = ProjectDocumentService(get_supabase_client())

        # Generate source_id with project prefix
        source_id = f"proj_{project_id}_file_{filename.replace(' ', '_')}_{uuid.uuid4().hex[:8]}"

        # Progress callback for project storage
        async def project_progress_callback(message: str, percentage: int, batch_info: dict = None):
            mapped_percentage = progress_mapper.map_progress("storing", percentage)
            await tracker.update(
                status="storing",
                progress=mapped_percentage,
                log=message,
                currentUrl=f"project://{project_id}/{filename}",
                **(batch_info or {})
            )

        # Upload to project-specific storage
        success, result = await project_doc_service.upload_document(
            project_id=project_id,
            file_content=extracted_text,
            filename=filename,
            source_id=source_id,
            knowledge_type=knowledge_type,
            tags=tag_list,
            extract_code_examples=extract_code_examples,
            is_project_private=is_project_private,
            progress_callback=project_progress_callback,
        )

        if not success:
            await tracker.error(result.get("error", "Upload failed"))
            return

        # Stage 3: Optionally promote to global KB
        if send_to_kb:
            await tracker.update(
                status="promoting",
                progress=95,
                log="Promoting to global knowledge base..."
            )

            kb_success, kb_result = await promote_to_knowledge_base(
                source_id=source_id,
                project_id=project_id,
                content=extracted_text,
                metadata={
                    "original_project": project_id,
                    "filename": filename,
                    "knowledge_type": knowledge_type,
                    "tags": tag_list,
                    "promoted_at": datetime.now().isoformat(),
                }
            )

            if not kb_success:
                logger.warning(f"KB promotion failed for {source_id}: {kb_result.get('error')}")

        # Stage 4: Completion
        await tracker.complete({
            "log": "Project document uploaded successfully!",
            "chunks_stored": result.get("chunks_stored"),
            "code_examples_stored": result.get("code_examples_stored", 0),
            "sourceId": result.get("source_id"),
            "project_id": project_id,
            "is_project_private": is_project_private,
            "promoted_to_kb": send_to_kb,
        })

    except Exception as e:
        error_msg = f"Upload failed: {str(e)}"
        await tracker.error(error_msg)
        logger.error(f"Project document upload failed: {e}", exc_info=True)

    finally:
        # Cleanup task registry
        if progress_id in active_crawl_tasks:
            del active_crawl_tasks[progress_id]
```

**Key Additions:**
- Project-specific source_id prefix (`proj_{project_id}_`)
- Separate service for project documents (`ProjectDocumentService`)
- Optional KB promotion stage (95-100%)
- Project metadata in completion data

### 5.6 API Client Method (Adapt This)

```typescript
// archon-ui-nextjs/src/lib/apiClient.ts

export interface ProjectUploadMetadata {
  knowledge_type?: "technical" | "business";
  tags?: string[];
  extract_code_examples?: boolean;
  is_project_private?: boolean;  // NEW
  send_to_kb?: boolean;  // NEW
}

export const projectDocumentsApi = {
  /**
   * Upload document to project with optional KB promotion
   */
  uploadDocument: async (
    projectId: string,
    file: File,
    metadata: ProjectUploadMetadata
  ): Promise<ProgressResponse> => {
    const formData = new FormData();
    formData.append("file", file);

    if (metadata.knowledge_type) {
      formData.append("knowledge_type", metadata.knowledge_type);
    }
    if (metadata.tags?.length) {
      formData.append("tags", JSON.stringify(metadata.tags));
    }
    if (metadata.extract_code_examples !== undefined) {
      formData.append("extract_code_examples", String(metadata.extract_code_examples));
    }
    if (metadata.is_project_private !== undefined) {
      formData.append("is_project_private", String(metadata.is_project_private));
    }
    if (metadata.send_to_kb !== undefined) {
      formData.append("send_to_kb", String(metadata.send_to_kb));
    }

    const response = await apiClient.post(
      `/api/projects/${projectId}/documents/upload`,
      formData,
      {
        headers: {
          "Content-Type": "multipart/form-data",
        },
      }
    );
    return response.data;
  },
};
```

---

## 6. Implementation Recommendations

### 6.1 What to Copy Exactly

**âœ… COPY WITHOUT MODIFICATION:**

1. **Frontend Components:**
   - `AddSourceDialog.tsx` structure (rename to `AddProjectDocumentDialog.tsx`)
   - Drag-and-drop file input (lines 418-469)
   - Tag management logic (lines 280-330, functions 143-172)
   - Toggle switch component (lines 363-389)
   - Submit button states (lines 403-409)

2. **Backend Utilities:**
   - `extract_text_from_document` function (all format handlers)
   - `ProgressTracker` class (entire file)
   - `ProgressMapper` class (entire file)
   - Text extraction utilities (`_preserve_code_blocks_across_pages`, `_clean_html_to_text`)

3. **API Patterns:**
   - FormData handling for file uploads
   - Immediate file content reading pattern
   - Tag JSON parsing + validation
   - Progress tracker initialization
   - Background task pattern with `asyncio.create_task`
   - Task registry for cancellation (`active_crawl_tasks`)

### 6.2 What to Adapt for Project Scoping

**ğŸ”§ MODIFY FOR PROJECT CONTEXT:**

1. **Frontend Dialog:**
   - Add project selector dropdown (if uploading from dashboard)
   - Change color scheme from purple to project theme
   - Add "Send to KB" toggle with confirmation modal
   - Add "Project Private" visibility toggle
   - Preload current project context

2. **Backend Endpoint:**
   - Change route from `/api/documents/upload` to `/api/projects/{project_id}/documents/upload`
   - Add `project_id` path parameter
   - Add `is_project_private` form field (default: True)
   - Add `send_to_kb` form field (default: False)
   - Validate project ownership/access

3. **Database Storage:**
   - Store in `archon_project_documents` table (not `archon_crawled_pages`)
   - Add `project_id` foreign key
   - Add `is_project_private` boolean column
   - Add `promoted_to_kb` boolean column
   - Add `promoted_at` timestamp

4. **Progress Tracking:**
   - Include `project_id` in tracker state
   - Update progress messages to include project context
   - Add KB promotion stage (if enabled)

### 6.3 What to Add (New Features)

**â• NEW FUNCTIONALITY:**

1. **"Send to KB" Checkbox:**
   ```tsx
   <div className="mb-4">
     <label className="flex cursor-pointer items-center justify-between">
       <div className="flex-1">
         <span className="text-sm font-medium text-gray-700 dark:text-gray-300">
           Send to Knowledge Base
         </span>
         <p className="mt-1 text-xs text-gray-500 dark:text-gray-400">
           Share this document with the global knowledge base
         </p>
       </div>
       <button
         type="button"
         onClick={() => {
           if (!sendToKB) {
             // Show confirmation modal first
             setSendToKBConfirmOpen(true);
           } else {
             setSendToKB(false);
           }
         }}
         className={`relative h-6 w-11 rounded-full transition-colors ${
           sendToKB ? "bg-green-500" : "bg-gray-300 dark:bg-gray-600"
         }`}
       >
         <span className={`absolute left-0.5 top-0.5 h-5 w-5 rounded-full bg-white shadow transition-transform ${
           sendToKB ? "translate-x-5" : "translate-x-0"
         }`} />
       </button>
     </label>
   </div>

   {/* Confirmation Modal */}
   {sendToKBConfirmOpen && (
     <div className="fixed inset-0 z-50 flex items-center justify-center bg-black/50">
       <div className="max-w-md rounded-lg bg-white p-6 dark:bg-gray-800">
         <h3 className="mb-4 text-lg font-bold">Confirm KB Promotion</h3>
         <p className="mb-6 text-sm text-gray-600 dark:text-gray-400">
           This document will be immediately available in the global knowledge base.
           All users will be able to search and reference it.
         </p>
         <div className="flex justify-end gap-2">
           <button
             onClick={() => setSendToKBConfirmOpen(false)}
             className="rounded-lg bg-gray-100 px-4 py-2 text-sm font-medium text-gray-700 hover:bg-gray-200"
           >
             Cancel
           </button>
           <button
             onClick={() => {
               setSendToKB(true);
               setSendToKBConfirmOpen(false);
             }}
             className="rounded-lg bg-green-600 px-4 py-2 text-sm font-medium text-white hover:bg-green-700"
           >
             Confirm
           </button>
         </div>
       </div>
     </div>
   )}
   ```

2. **Project Context Awareness:**
   ```typescript
   // Load current project context
   useEffect(() => {
     if (isOpen && currentProjectId) {
       // Preselect current project
       setSelectedProjectId(currentProjectId);

       // Load project-specific tag suggestions
       fetch(`/api/projects/${currentProjectId}/tag-suggestions`)
         .then(res => res.json())
         .then(data => setTagSuggestions(data.tags));
     }
   }, [isOpen, currentProjectId]);
   ```

3. **Project-Private Toggle:**
   ```tsx
   <div className="mb-4">
     <label className="flex cursor-pointer items-center justify-between">
       <span className="text-sm font-medium text-gray-700 dark:text-gray-300">
         Project Private
       </span>
       <button
         type="button"
         onClick={() => setIsProjectPrivate(!isProjectPrivate)}
         className={`relative h-6 w-11 rounded-full transition-colors ${
           isProjectPrivate ? "bg-cyan-500" : "bg-gray-300 dark:bg-gray-600"
         }`}
       >
         <span className={`absolute left-0.5 top-0.5 h-5 w-5 rounded-full bg-white shadow transition-transform ${
           isProjectPrivate ? "translate-x-5" : "translate-x-0"
         }`} />
       </button>
     </label>
     <p className="mt-1 text-xs text-gray-500 dark:text-gray-400">
       Only project members can access this document
     </p>
   </div>
   ```

4. **Backend KB Promotion Function:**
   ```python
   async def promote_to_knowledge_base(
       source_id: str,
       project_id: str,
       content: str,
       metadata: dict,
   ) -> tuple[bool, dict]:
       """
       Promote project document to global knowledge base.

       Creates a copy in archon_crawled_pages with reference to original project.
       """
       try:
           kb_service = KnowledgeBaseService(get_supabase_client())

           # Create KB source with project reference
           kb_source_id = f"kb_promoted_{source_id}"

           success, result = await kb_service.store_document(
               source_id=kb_source_id,
               content=content,
               metadata={
                   **metadata,
                   "promoted_from_project": project_id,
                   "original_source_id": source_id,
                   "is_promoted": True,
               },
           )

           if success:
               # Update project document record
               await update_project_document_promotion_status(
                   source_id=source_id,
                   promoted_to_kb=True,
                   kb_source_id=kb_source_id,
               )

           return success, result

       except Exception as e:
           logger.error(f"KB promotion failed: {e}", exc_info=True)
           return False, {"error": str(e)}
   ```

5. **Task Linking Integration:**
   - Add "Link to Task" button in upload confirmation
   - Auto-suggest tasks related to uploaded document
   - Store document-task relationships in `archon_task_sources`

### 6.4 Suggested Component/Endpoint Names

**Frontend Components:**
- `AddProjectDocumentDialog.tsx` (copy of `AddSourceDialog.tsx`)
- `ProjectDocumentProgress.tsx` (copy of `CrawlingProgress.tsx`)
- `ProjectDocumentCard.tsx` (display uploaded documents)
- `SendToKBConfirmModal.tsx` (confirmation dialog)

**Backend Routes:**
- `POST /api/projects/{project_id}/documents/upload` (main upload)
- `POST /api/projects/{project_id}/documents/crawl` (optional URL crawl)
- `GET /api/projects/{project_id}/documents` (list documents)
- `POST /api/projects/{project_id}/documents/{doc_id}/promote` (manual KB promotion)
- `DELETE /api/projects/{project_id}/documents/{doc_id}` (delete document)

**Database Tables:**
- `archon_project_documents` (main storage)
  - Columns: `id`, `project_id`, `source_id`, `filename`, `knowledge_type`, `tags`, `is_project_private`, `promoted_to_kb`, `kb_source_id`, `created_at`, `updated_at`
- `archon_project_document_chunks` (text chunks with embeddings)
- `archon_project_code_examples` (extracted code snippets)

---

## 7. Technical Details

### 7.1 File Types Supported

**Implemented in `extract_text_from_document`:**

| Format | Extension | MIME Type | Library | Notes |
|--------|-----------|-----------|---------|-------|
| **PDF** | .pdf | application/pdf | pdfplumber â†’ PyPDF2 | Page markers, code block preservation |
| **Word** | .docx | application/vnd.openxmlformats-officedocument.wordprocessingml.document | python-docx | Paragraphs + tables |
| **Word Legacy** | .doc | application/msword | python-docx | Limited support |
| **HTML** | .html, .htm | text/html | regex | Tag cleaning, code block preservation |
| **Text** | .txt | text/plain | Built-in | UTF-8 decode |
| **Markdown** | .md, .markdown | text/markdown | Built-in | UTF-8 decode |
| **reStructuredText** | .rst | text/x-rst | Built-in | UTF-8 decode |

**File Size Limits:**
- Not explicitly enforced in code
- Recommend: 50 MB max (FastAPI default is 100 MB)
- Add in project upload endpoint: `File(..., max_length=50*1024*1024)`

### 7.2 Text Extraction Methods

**PDF Extraction:**
1. **Primary:** pdfplumber (better for complex layouts, tables, forms)
2. **Fallback:** PyPDF2 (simpler, more reliable for text-only PDFs)
3. **Page Markers:** `--- Page N ---` separators between pages
4. **Code Block Handling:** Rejoins split code blocks across page boundaries

**DOCX Extraction:**
- Iterates paragraphs: `doc.paragraphs`
- Iterates tables: `doc.tables`
- Table cells: pipe-delimited (`|`)
- Preserves document structure

**HTML Cleaning:**
- Extracts code blocks first (placeholder replacement)
- Removes `<script>` and `<style>` tags
- Converts structural tags (headers, paragraphs, lists) to text
- Cleans HTML entities (`&nbsp;`, `&lt;`, etc.)
- Restores code blocks as markdown (` ```...``` `)
- Collapses excessive whitespace

**Text Files:**
- UTF-8 decode with error handling (`errors="ignore"`)
- Strips leading/trailing whitespace
- Validates non-empty content

### 7.3 Progress Tracking Intervals

**Polling Interval:**
- Frontend: 1000ms (1 second) via TanStack Query
- Backend: Synchronous updates (no polling, class-level dict)
- Auto-cleanup: 30 seconds after terminal state (completed, error, cancelled)

**Progress Stages:**

| Stage | Upload Range | Crawl Range | Duration Estimate |
|-------|--------------|-------------|-------------------|
| initializing | 0-1% | 0-1% | < 1 second |
| processing | 15-20% | 15-20% | 5-30 seconds (text extraction) |
| storing | 30-100% | 25-40% | 30-300 seconds (embeddings) |
| code_extraction | (if enabled) | 40-90% | 30-180 seconds (LLM summaries) |
| completed | 100% | 100% | - |

**Never-Go-Backwards Protection:**
1. `ProgressMapper.map_progress()` - Ensures mapped progress â‰¥ `last_overall_progress`
2. `ProgressTracker.update()` - Ensures updated progress â‰¥ `current_progress`
3. `OperationCard` component - Frontend display uses `Math.max(current, previous)`

### 7.4 Error Handling Patterns

**Backend Error Hierarchy:**

1. **User Errors (ValueError):**
   - Unsupported file format
   - Empty file
   - Invalid file structure
   - â†’ Display user-friendly message, don't log traceback

2. **System Errors (Exception):**
   - PDF extraction failure
   - Embedding generation failure
   - Database connection errors
   - â†’ Log full traceback, display generic message

**Example:**
```python
try:
    extracted_text = extract_text_from_document(file_content, filename, content_type)
except ValueError as ex:
    # User error - show message directly
    logger.warning(f"Document validation failed: {filename} - {str(ex)}")
    await tracker.error(str(ex))
    return
except Exception as ex:
    # System error - log traceback
    logger.error(f"Failed to extract text from document: {filename}", exc_info=True)
    await tracker.error(f"Failed to extract text from document: {str(ex)}")
    return
```

**Frontend Error Display:**
```typescript
try {
  await onUpload(selectedFile, metadata);
  resetForm();
  onClose();
} catch (err) {
  // Show error in dialog (red border, error message)
  setError(err instanceof Error ? err.message : "Failed to upload document");
}
```

### 7.5 Cancellation Support

**Task Registry Pattern:**

```python
# Global task registry (module-level)
active_crawl_tasks: dict[str, asyncio.Task] = {}

# Register task on creation
upload_task = asyncio.create_task(_perform_upload_with_progress(...))
active_crawl_tasks[progress_id] = upload_task

# Cancellation endpoint
@router.post("/api/knowledge-items/stop/{progress_id}")
async def stop_operation(progress_id: str):
    task = active_crawl_tasks.get(progress_id)
    if task:
        task.cancel()
        await tracker.update(status="cancelled", progress=0, log="Operation cancelled by user")
    return {"success": True, "message": "Operation cancelled"}

# Check cancellation in processing loop
def check_upload_cancellation():
    task = active_crawl_tasks.get(progress_id)
    if task and task.cancelled():
        raise asyncio.CancelledError("Document upload was cancelled by user")

# Cleanup in finally block
finally:
    if progress_id in active_crawl_tasks:
        del active_crawl_tasks[progress_id]
```

**Service Layer Integration:**
```python
# Document storage service checks cancellation before expensive operations
await doc_storage_service.upload_document(
    ...,
    cancellation_check=check_upload_cancellation  # Passed as callback
)

# Service calls cancellation_check() periodically
for batch in batches:
    cancellation_check()  # Raises CancelledError if cancelled
    await process_batch(batch)
```

---

## 8. Common Pitfalls to Avoid

### 8.1 Critical Issues from Existing Code

**âŒ DON'T:**

1. **Read file in background task**
   ```python
   # BAD: File may be closed by the time background task runs
   upload_task = asyncio.create_task(process_upload(file))

   # GOOD: Read file content immediately
   file_content = await file.read()
   upload_task = asyncio.create_task(process_upload(file_content))
   ```

2. **Skip progress tracker initialization**
   ```python
   # BAD: Start task immediately, tracker initialized inside
   upload_task = asyncio.create_task(_perform_upload(...))

   # GOOD: Initialize tracker BEFORE starting task
   tracker = ProgressTracker(progress_id, "upload")
   await tracker.start({...})
   upload_task = asyncio.create_task(_perform_upload(..., tracker))
   ```

3. **Allow progress to go backwards**
   ```python
   # BAD: Direct assignment
   self.state["progress"] = new_progress

   # GOOD: Never-go-backwards check
   current_progress = self.state.get("progress", 0)
   actual_progress = max(current_progress, new_progress)
   self.state["progress"] = actual_progress
   ```

4. **Skip stage range mapping**
   ```python
   # BAD: Use raw stage progress
   await tracker.update(status="storing", progress=50, ...)

   # GOOD: Map to overall progress
   mapped_progress = progress_mapper.map_progress("storing", 50)
   await tracker.update(status="storing", progress=mapped_progress, ...)
   ```

5. **Parse tags as array instead of JSON string**
   ```python
   # BAD: FastAPI Form expects JSON string
   tags: list[str] = Form([])  # Won't work!

   # GOOD: Parse JSON string
   tags: str | None = Form(None)
   tag_list = json.loads(tags) if tags else []
   ```

6. **Forget task registry cleanup**
   ```python
   # BAD: Memory leak
   active_crawl_tasks[progress_id] = upload_task
   # ... no cleanup

   # GOOD: Cleanup in finally block
   try:
       await process_upload()
   finally:
       if progress_id in active_crawl_tasks:
           del active_crawl_tasks[progress_id]
   ```

7. **Skip file validation**
   ```python
   # BAD: Assume file is valid
   text = extract_text_from_document(file_content, filename, content_type)

   # GOOD: Handle ValueError for user errors
   try:
       text = extract_text_from_document(...)
   except ValueError as ex:
       await tracker.error(str(ex))  # Show to user
       return
   ```

8. **Use synchronous operations in async functions**
   ```python
   # BAD: Blocking operation
   result = some_sync_function()

   # GOOD: Run in executor
   loop = asyncio.get_event_loop()
   result = await loop.run_in_executor(None, some_sync_function)
   ```

### 8.2 Project-Specific Pitfalls

**âŒ DON'T:**

1. **Store project documents in global KB table**
   - Use separate `archon_project_documents` table
   - Add `project_id` foreign key
   - Implement row-level security (RLS) policies

2. **Skip project ownership validation**
   ```python
   # BAD: Trust project_id from client
   await upload_document(project_id, ...)

   # GOOD: Validate access
   project = await project_service.get_project(project_id)
   if not project or not await has_project_access(user_id, project_id):
       raise HTTPException(403, "Access denied")
   ```

3. **Auto-promote all documents to KB**
   - Default `send_to_kb=False`
   - Require explicit user confirmation
   - Log all promotions for audit trail

4. **Forget to update task-document links**
   - When promoting to KB, update task sources
   - Maintain bidirectional relationships
   - Clean up orphaned links

---

## 9. Testing Recommendations

### 9.1 Unit Tests

**Backend (pytest):**

```python
# test_project_upload.py

@pytest.mark.asyncio
async def test_upload_document_success():
    """Test successful document upload"""
    # Arrange
    file_content = b"Test document content"
    file_metadata = {
        "filename": "test.txt",
        "content_type": "text/plain",
        "size": len(file_content),
    }
    tracker = ProgressTracker("test-123", "upload")

    # Act
    await _perform_project_upload_with_progress(
        "test-123", "project-1", file_content, file_metadata,
        ["tag1"], "technical", True, True, False, tracker
    )

    # Assert
    state = tracker.get_state()
    assert state["status"] == "completed"
    assert state["progress"] == 100

@pytest.mark.asyncio
async def test_upload_invalid_file_format():
    """Test upload with unsupported format"""
    file_content = b"\x00\x01\x02"  # Binary garbage

    with pytest.raises(ValueError, match="Unsupported file format"):
        extract_text_from_document(file_content, "test.xyz", "application/octet-stream")

@pytest.mark.asyncio
async def test_progress_never_goes_backwards():
    """Test progress never decreases"""
    mapper = ProgressMapper()

    # Stage 1 ends at 40%
    progress_1 = mapper.map_progress("processing", 100)
    assert progress_1 >= 20

    # Stage 2 starts - should not drop below 40%
    progress_2 = mapper.map_progress("storing", 0)
    assert progress_2 >= progress_1

def test_tag_parsing():
    """Test tag JSON parsing"""
    # Valid JSON array
    tags = '["tag1", "tag2"]'
    result = json.loads(tags)
    assert result == ["tag1", "tag2"]

    # Invalid JSON
    with pytest.raises(json.JSONDecodeError):
        json.loads('["tag1", "tag2"')
```

**Frontend (Jest + React Testing Library):**

```typescript
// AddProjectDocumentDialog.test.tsx

describe("AddProjectDocumentDialog", () => {
  it("renders upload tab by default", () => {
    render(<AddProjectDocumentDialog isOpen={true} onClose={jest.fn()} />);
    expect(screen.getByText("Upload Document")).toBeInTheDocument();
  });

  it("validates file selection", async () => {
    const onUpload = jest.fn();
    render(<AddProjectDocumentDialog isOpen={true} onUpload={onUpload} />);

    // Try to submit without file
    fireEvent.click(screen.getByText("Upload Document"));
    expect(screen.getByText("Please select a file to upload")).toBeVisible();
  });

  it("adds tags on Enter key", async () => {
    render(<AddProjectDocumentDialog isOpen={true} />);

    const input = screen.getByPlaceholderText("Press Enter to add tags");
    fireEvent.change(input, { target: { value: "test-tag" } });
    fireEvent.keyPress(input, { key: "Enter", charCode: 13 });

    expect(screen.getByText("test-tag")).toBeInTheDocument();
  });

  it("prevents duplicate tags", async () => {
    render(<AddProjectDocumentDialog isOpen={true} />);

    // Add tag twice
    const input = screen.getByPlaceholderText("Press Enter to add tags");
    fireEvent.change(input, { target: { value: "test-tag" } });
    fireEvent.keyPress(input, { key: "Enter" });
    fireEvent.change(input, { target: { value: "test-tag" } });
    fireEvent.keyPress(input, { key: "Enter" });

    // Should only appear once
    const tags = screen.getAllByText("test-tag");
    expect(tags).toHaveLength(1);
  });
});
```

### 9.2 Integration Tests

**E2E (Playwright):**

```typescript
// project-document-upload.spec.ts

test("upload document to project with KB promotion", async ({ page }) => {
  // Navigate to project detail page
  await page.goto("/projects/test-project-1");

  // Open upload dialog
  await page.click('[data-testid="add-document-button"]');

  // Select file
  const fileInput = await page.locator('input[type="file"]');
  await fileInput.setInputFiles("./test-fixtures/sample.pdf");

  // Configure options
  await page.selectOption('[name="knowledge_type"]', 'technical');
  await page.fill('[name="tags"]', 'architecture');
  await page.keyboard.press('Enter');

  // Enable "Send to KB"
  await page.click('[data-testid="send-to-kb-toggle"]');
  await page.click('button:has-text("Confirm")'); // Confirmation modal

  // Upload
  await page.click('button:has-text("Upload Document")');

  // Wait for progress bar
  await expect(page.locator('[data-testid="progress-bar"]')).toBeVisible();

  // Wait for completion (max 2 minutes)
  await expect(page.locator('text=Document uploaded successfully')).toBeVisible({ timeout: 120000 });

  // Verify document appears in list
  await expect(page.locator('text=sample.pdf')).toBeVisible();

  // Verify KB promotion
  await page.goto("/knowledge-base");
  await expect(page.locator('text=sample.pdf')).toBeVisible();
});

test("cancel document upload mid-process", async ({ page }) => {
  await page.goto("/projects/test-project-1");
  await page.click('[data-testid="add-document-button"]');

  // Upload large file
  const fileInput = await page.locator('input[type="file"]');
  await fileInput.setInputFiles("./test-fixtures/large-document.pdf");
  await page.click('button:has-text("Upload Document")');

  // Wait for progress to start
  await expect(page.locator('[data-testid="progress-bar"]')).toBeVisible();
  await page.waitForTimeout(5000); // Let it process a bit

  // Cancel
  await page.click('button:has-text("Stop")');
  await page.click('button:has-text("OK")'); // Confirmation

  // Verify cancelled state
  await expect(page.locator('text=Operation cancelled')).toBeVisible();
});
```

### 9.3 Performance Tests

**Load Testing (Locust):**

```python
# locustfile.py

from locust import HttpUser, task, between

class ProjectDocumentUploadUser(HttpUser):
    wait_time = between(1, 3)

    @task
    def upload_document(self):
        # Simulate document upload
        files = {"file": ("test.txt", "Sample document content", "text/plain")}
        data = {
            "knowledge_type": "technical",
            "tags": '["test"]',
            "extract_code_examples": "true",
            "is_project_private": "true",
            "send_to_kb": "false",
        }

        with self.client.post(
            "/api/projects/test-project-1/documents/upload",
            files=files,
            data=data,
            catch_response=True,
        ) as response:
            if response.status_code == 200:
                progress_id = response.json().get("progressId")

                # Poll progress
                for _ in range(60):  # Poll for up to 60 seconds
                    progress_response = self.client.get(f"/api/progress/{progress_id}")
                    status = progress_response.json().get("status")

                    if status == "completed":
                        response.success()
                        break
                    elif status in ["error", "failed", "cancelled"]:
                        response.failure(f"Upload failed with status: {status}")
                        break

                    time.sleep(1)
            else:
                response.failure(f"Upload request failed: {response.status_code}")
```

**Run:**
```bash
locust -f locustfile.py --users 10 --spawn-rate 2 --host http://localhost:8181
```

---

## 10. Performance Considerations

### 10.1 Optimization Opportunities

**Backend:**
1. **Parallel embedding generation**
   - Batch embeddings in groups of 10-20
   - Use `asyncio.gather()` for concurrent API calls
   - Monitor rate limits (OpenAI: 3,500 TPM for text-embedding-3-small)

2. **Streaming file processing**
   - For very large files (>10 MB), process in chunks
   - Stream embeddings to database as generated
   - Avoid loading entire file in memory

3. **Code extraction caching**
   - Cache LLM summaries for identical code blocks
   - Use content hash as cache key
   - Reduces duplicate API calls

4. **Progress polling optimization**
   - Use WebSockets for real-time updates (future enhancement)
   - Reduce polling interval when status is stable
   - Exponential backoff for completed operations

**Frontend:**
1. **Debounce tag input**
   - Wait 300ms after user stops typing before validation
   - Prevents excessive re-renders

2. **Lazy load progress history**
   - Only load last 50 log entries initially
   - Paginate older logs on demand

3. **Memoize progress calculations**
   - Use `useMemo` for expensive calculations
   - Prevent re-renders when progress unchanged

### 10.2 Scalability Considerations

**Horizontal Scaling:**
- Progress states in Redis (not class-level dict)
- Task queue (Celery, RQ) for background processing
- Distributed file storage (S3, Azure Blob)

**Vertical Scaling:**
- Increase worker threads for concurrent uploads
- Add memory for larger file buffers
- Use dedicated GPU for embedding generation

---

## 11. Security Considerations

### 11.1 File Upload Security

**Input Validation:**
```python
# Validate file size
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB
if len(file_content) > MAX_FILE_SIZE:
    raise HTTPException(400, "File too large (max 50 MB)")

# Validate file type
ALLOWED_EXTENSIONS = {".txt", ".md", ".pdf", ".doc", ".docx", ".html", ".htm"}
if not any(filename.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS):
    raise HTTPException(400, f"Unsupported file type: {filename}")

# Sanitize filename
import re
safe_filename = re.sub(r'[^a-zA-Z0-9_.-]', '_', filename)
```

**Content Scanning:**
```python
# Optional: Virus scanning (ClamAV)
import pyclamd
cd = pyclamd.ClamdUnixSocket()
scan_result = cd.scan_stream(file_content)
if scan_result:
    raise HTTPException(400, "File contains malicious content")
```

**Access Control:**
```python
# Validate project access
async def validate_project_access(project_id: str, user_id: str) -> bool:
    project = await project_service.get_project(project_id)
    if not project:
        return False

    # Check project membership
    is_member = await project_service.is_member(project_id, user_id)

    # Check project visibility
    if project.is_private and not is_member:
        return False

    return True
```

### 11.2 Data Privacy

**Project-Private Documents:**
- Store in separate table (`archon_project_documents`)
- Implement Row-Level Security (RLS) in Supabase
- Filter by `project_id` in all queries
- Log all access attempts

**KB Promotion:**
- Require explicit user confirmation
- Log promotion events with user_id, timestamp
- Add "promoted_by" metadata to KB records
- Allow rollback (unpromote) within 24 hours

---

## 12. Monitoring & Logging

### 12.1 Key Metrics to Track

**Upload Performance:**
- Average upload time by file size
- Text extraction time by format
- Embedding generation time
- Success/failure rates
- Cancellation rates

**Progress Tracking:**
- Average polling requests per upload
- Progress state memory usage
- Auto-cleanup execution count
- Stage transition times

**Error Rates:**
- Unsupported format rejections
- Text extraction failures
- Embedding generation failures
- Database storage errors

### 12.2 Logging Best Practices

```python
# Structured logging with context
safe_logfire_info(
    f"Document upload started | "
    f"progress_id={progress_id} | "
    f"project_id={project_id} | "
    f"filename={filename} | "
    f"file_size={file_size} | "
    f"knowledge_type={knowledge_type} | "
    f"is_project_private={is_project_private} | "
    f"send_to_kb={send_to_kb}"
)

# Error logging with traceback
try:
    extracted_text = extract_text_from_document(...)
except Exception as e:
    logger.error(
        f"Text extraction failed | "
        f"progress_id={progress_id} | "
        f"filename={filename} | "
        f"error={str(e)}",
        exc_info=True  # Include full traceback
    )
    safe_logfire_error(f"Text extraction failed | error={str(e)}")
```

---

## 13. Conclusion

### Summary of Findings

The Archon knowledge base upload system provides a **production-ready foundation** for implementing project-scoped document uploads. Key strengths include:

1. **Robust dual-input model** - Proven URL crawling + file upload patterns
2. **Comprehensive file format support** - PDF, DOCX, HTML, TXT, MD with intelligent text extraction
3. **Battle-tested progress tracking** - Never-go-backwards guarantees, auto-cleanup, polling architecture
4. **Cancellation-safe processing** - Task registry, cleanup patterns, graceful error handling
5. **Reusable UI components** - Drag-and-drop, tag management, toggles, progress bars

### Implementation Checklist

**Phase 1: Copy Existing Patterns (Week 1)**
- [ ] Copy `AddSourceDialog.tsx` â†’ `AddProjectDocumentDialog.tsx`
- [ ] Copy `CrawlingProgress.tsx` â†’ `ProjectDocumentProgress.tsx`
- [ ] Copy backend utilities (`extract_text_from_document`, `ProgressTracker`, `ProgressMapper`)
- [ ] Copy API client methods (`uploadDocument`)
- [ ] Test all copied components in isolation

**Phase 2: Add Project Scoping (Week 2)**
- [ ] Create `archon_project_documents` table with `project_id` FK
- [ ] Create `POST /api/projects/{project_id}/documents/upload` endpoint
- [ ] Add `is_project_private` field (default: True)
- [ ] Implement project ownership validation
- [ ] Add project context awareness to frontend dialog
- [ ] Test project-scoped uploads

**Phase 3: Add KB Promotion (Week 3)**
- [ ] Add "Send to KB" toggle with confirmation modal
- [ ] Implement `promote_to_knowledge_base()` function
- [ ] Add KB promotion stage to progress tracking (95-100%)
- [ ] Create audit log for promotions
- [ ] Test promotion workflow end-to-end

**Phase 4: Integration & Testing (Week 4)**
- [ ] Integrate with task linking system
- [ ] Add document-task relationship tracking
- [ ] Write unit tests (backend + frontend)
- [ ] Write integration tests (E2E)
- [ ] Performance testing with large files
- [ ] Security review

**Phase 5: Deployment (Week 5)**
- [ ] Database migrations
- [ ] Feature flag deployment
- [ ] Gradual rollout to beta users
- [ ] Monitor metrics and error rates
- [ ] Collect user feedback
- [ ] Full production release

### Next Steps

1. **Review this document** with UI and backend developers
2. **Create Archon tasks** for each phase using the checklist above
3. **Set up test fixtures** (sample PDFs, DOCX, etc.)
4. **Establish monitoring** (Sentry, Logfire, custom dashboards)
5. **Begin implementation** starting with Phase 1 (copy patterns)

### Contact for Questions

- **Architecture Questions:** Refer to this document first
- **Implementation Blockers:** Check GitHub issues or Archon knowledge base
- **Code Examples:** See "Reusable Code Patterns" section above

---

**End of Research Document**

**Last Updated:** 2026-01-23
**Analyst:** Codebase Analyst Agent
**Status:** âœ… Complete and Approved for Implementation
