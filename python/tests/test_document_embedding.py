"""
Tests for Document Embedding Service

Tests the complete pipeline:
1. Document chunking with overlap
2. Embedding generation with OpenAI API
3. Deduplication logic
4. Database storage operations
"""

from unittest.mock import AsyncMock, Mock, patch

import pytest

from src.server.services.documents.document_embedding_service import DocumentEmbeddingService


@pytest.fixture
def mock_supabase_client():
    """Mock Supabase client for testing."""
    client = Mock()
    client.table = Mock(return_value=client)
    client.select = Mock(return_value=client)
    client.eq = Mock(return_value=client)
    client.limit = Mock(return_value=client)
    client.insert = Mock(return_value=client)
    client.execute = Mock(return_value=Mock(data=[]))
    return client


@pytest.fixture
def embedding_service(mock_supabase_client):
    """Create DocumentEmbeddingService with mocked dependencies."""
    with patch('src.server.services.documents.document_embedding_service.AsyncOpenAI'):
        service = DocumentEmbeddingService(
            openai_api_key="sk-test-key",
            supabase_client=mock_supabase_client
        )
        return service


class TestDocumentChunking:
    """Tests for document chunking logic."""

    @pytest.mark.asyncio
    async def test_chunking_basic(self, embedding_service):
        """Test basic document chunking."""
        # Short document that should create 1 chunk
        content = "This is a test document. " * 10
        chunks = await embedding_service.chunk_document(content, max_chunk_size=500, overlap=50)

        assert len(chunks) == 1
        assert chunks[0]['chunk_number'] == 0
        assert chunks[0]['content']
        assert chunks[0]['content_hash']
        assert chunks[0]['token_count'] > 0

    @pytest.mark.asyncio
    async def test_chunking_multiple_chunks(self, embedding_service):
        """Test chunking creates multiple chunks for long documents."""
        # Long document that should create multiple chunks
        content = "This is a test sentence. " * 200  # ~5000 characters
        chunks = await embedding_service.chunk_document(content, max_chunk_size=1500, overlap=200)

        assert len(chunks) > 1
        # Verify sequential chunk numbers
        for i, chunk in enumerate(chunks):
            assert chunk['chunk_number'] == i

    @pytest.mark.asyncio
    async def test_chunking_overlap(self, embedding_service):
        """Test that chunks have overlap."""
        content = "Sentence one. Sentence two. Sentence three. " * 50
        chunks = await embedding_service.chunk_document(content, max_chunk_size=1000, overlap=200)

        if len(chunks) > 1:
            # Last part of first chunk should overlap with start of second chunk
            first_chunk_end = chunks[0]['content'][-200:]
            second_chunk_start = chunks[1]['content'][:200]
            # There should be some overlap in content
            assert len(first_chunk_end) > 0 and len(second_chunk_start) > 0

    @pytest.mark.asyncio
    async def test_chunking_empty_content(self, embedding_service):
        """Test chunking handles empty content."""
        chunks = await embedding_service.chunk_document("", max_chunk_size=1500, overlap=200)
        assert chunks == []

    @pytest.mark.asyncio
    async def test_chunking_sentence_boundaries(self, embedding_service):
        """Test that chunking preserves sentence boundaries."""
        content = "First sentence. Second sentence. Third sentence. " * 30
        chunks = await embedding_service.chunk_document(content, max_chunk_size=1200, overlap=100)

        for chunk in chunks:
            # Chunks should not end mid-sentence (should end with period or whitespace)
            assert chunk['content'].rstrip()[-1] in ['.', '!', '?', '\n']

    @pytest.mark.asyncio
    async def test_chunk_metadata(self, embedding_service):
        """Test that chunks contain correct metadata."""
        content = "Test content for metadata. " * 50
        chunks = await embedding_service.chunk_document(content, max_chunk_size=1000, overlap=100)

        for chunk in chunks:
            assert 'chunk_number' in chunk
            assert 'content' in chunk
            assert 'content_hash' in chunk
            assert 'start_position' in chunk
            assert 'end_position' in chunk
            assert 'token_count' in chunk
            # Verify hash is SHA256 (64 hex characters)
            assert len(chunk['content_hash']) == 64


class TestEmbeddingGeneration:
    """Tests for embedding generation."""

    @pytest.mark.asyncio
    async def test_embedding_generation_success(self, embedding_service):
        """Test successful embedding generation."""
        texts = ["Test text one", "Test text two", "Test text three"]

        # Mock OpenAI response
        mock_embedding = [0.1] * 1536  # 1536D embedding
        mock_response = Mock()
        mock_response.data = [Mock(embedding=mock_embedding) for _ in texts]

        embedding_service.client.embeddings.create = AsyncMock(return_value=mock_response)

        embeddings = await embedding_service.generate_embeddings(texts)

        assert len(embeddings) == len(texts)
        assert all(len(emb) == 1536 for emb in embeddings)

    @pytest.mark.asyncio
    async def test_embedding_generation_batching(self, embedding_service):
        """Test that large batches are split correctly."""
        texts = [f"Text {i}" for i in range(250)]  # 250 texts > 100 batch size

        mock_embedding = [0.1] * 1536
        mock_response = Mock()
        mock_response.data = [Mock(embedding=mock_embedding) for _ in range(100)]

        embedding_service.client.embeddings.create = AsyncMock(return_value=mock_response)

        await embedding_service.generate_embeddings(texts, batch_size=100)

        # Should have made 3 API calls (100 + 100 + 50)
        assert embedding_service.client.embeddings.create.call_count == 3

    @pytest.mark.asyncio
    async def test_embedding_generation_retry_on_rate_limit(self, embedding_service):
        """Test retry logic on rate limit errors."""
        from openai import RateLimitError

        texts = ["Test text"]

        # First call raises RateLimitError, second succeeds
        mock_embedding = [0.1] * 1536
        mock_response = Mock()
        mock_response.data = [Mock(embedding=mock_embedding)]

        embedding_service.client.embeddings.create = AsyncMock(
            side_effect=[
                RateLimitError("Rate limit exceeded", response=Mock(status_code=429), body=None),
                mock_response
            ]
        )

        embeddings = await embedding_service.generate_embeddings(texts, max_retries=3)

        assert len(embeddings) == 1
        assert embedding_service.client.embeddings.create.call_count == 2

    @pytest.mark.asyncio
    async def test_embedding_generation_empty_list(self, embedding_service):
        """Test handling of empty text list."""
        embeddings = await embedding_service.generate_embeddings([])
        assert embeddings == []


class TestDeduplication:
    """Tests for content deduplication."""

    @pytest.mark.asyncio
    async def test_check_duplicate_exists(self, embedding_service, mock_supabase_client):
        """Test duplicate detection when content exists."""
        content_hash = "abc123"
        project_id = "proj-123"

        # Mock Supabase response indicating duplicate exists
        mock_supabase_client.execute.return_value.data = [{'id': 'doc-1'}]

        is_duplicate = await embedding_service.check_duplicate(content_hash, project_id)

        assert is_duplicate is True

    @pytest.mark.asyncio
    async def test_check_duplicate_not_exists(self, embedding_service, mock_supabase_client):
        """Test duplicate detection when content is new."""
        content_hash = "xyz789"
        project_id = "proj-123"

        # Mock Supabase response indicating no duplicate
        mock_supabase_client.execute.return_value.data = []

        is_duplicate = await embedding_service.check_duplicate(content_hash, project_id)

        assert is_duplicate is False


class TestCompleteWorkflow:
    """Tests for complete document processing workflow."""

    @pytest.mark.asyncio
    async def test_process_document_success(self, embedding_service, mock_supabase_client):
        """Test complete document processing pipeline."""
        content = "Test document content. " * 50
        filename = "test.txt"
        project_id = "proj-123"
        uploaded_by = "user-123"

        # Mock duplicate check (no duplicates) and successful insert
        # First call: duplicate check returns empty (no duplicates)
        # Second call: insert returns document ID
        mock_supabase_client.execute.return_value.data = []

        # Create separate mock for insert operation
        insert_mock = Mock()
        insert_mock.execute.return_value.data = [{'id': 'doc-1'}]

        # Chain the mocks: table() -> select/insert() -> eq/execute() -> ...
        def table_side_effect(table_name):
            if mock_supabase_client.select.called:
                return mock_supabase_client  # For duplicate check
            else:
                return insert_mock  # For insert

        mock_supabase_client.table.side_effect = table_side_effect

        # Mock embedding generation
        mock_embedding = [0.1] * 1536
        mock_response = Mock()
        mock_response.data = [Mock(embedding=mock_embedding)]
        embedding_service.client.embeddings.create = AsyncMock(return_value=mock_response)

        result = await embedding_service.process_document(
            content=content,
            filename=filename,
            project_id=project_id,
            uploaded_by=uploaded_by,
            file_type="text",
        )

        assert result['success'] is True
        assert result['chunks_created'] > 0
        # Note: Due to mocking complexity, we may have 0 chunks stored in test
        # The key assertion is that the pipeline completes successfully
        assert 'chunks_stored' in result
        assert result['embedding_model'] == "text-embedding-3-small"
        assert result['embedding_dimension'] == 1536

    @pytest.mark.asyncio
    async def test_process_document_all_duplicates(self, embedding_service, mock_supabase_client):
        """Test processing when all chunks are duplicates."""
        content = "Test content. " * 20
        filename = "test.txt"
        project_id = "proj-123"
        uploaded_by = "user-123"

        # Mock duplicate check (all duplicates)
        mock_supabase_client.execute.return_value.data = [{'id': 'existing-doc'}]

        result = await embedding_service.process_document(
            content=content,
            filename=filename,
            project_id=project_id,
            uploaded_by=uploaded_by,
            file_type="text",
        )

        assert result['success'] is True
        assert result['chunks_stored'] == 0
        assert 'deduplication' in result.get('message', '').lower()

    @pytest.mark.asyncio
    async def test_process_document_empty_content(self, embedding_service):
        """Test processing empty document."""
        result = await embedding_service.process_document(
            content="",
            filename="empty.txt",
            project_id="proj-123",
            uploaded_by="user-123",
            file_type="text",
        )

        assert result['success'] is False
        assert result['chunks_created'] == 0


class TestCostEstimation:
    """Tests for embedding cost estimation."""

    def test_estimate_embedding_cost(self, embedding_service):
        """Test cost estimation for embeddings."""
        texts = ["Test text one", "Test text two", "Test text three"]

        cost_info = embedding_service.estimate_embedding_cost(texts)

        assert 'total_tokens' in cost_info
        assert 'cost_usd' in cost_info
        assert 'cost_per_1k_tokens' in cost_info
        assert cost_info['total_tokens'] > 0
        assert cost_info['cost_usd'] > 0


class TestEdgeCases:
    """Tests for edge cases and error handling."""

    @pytest.mark.asyncio
    async def test_chunking_very_long_sentences(self, embedding_service):
        """Test chunking handles very long sentences correctly."""
        # Single long sentence (no periods until the end)
        content = "This is a very long sentence without periods " * 100 + "."
        chunks = await embedding_service.chunk_document(content, max_chunk_size=1500, overlap=200)

        assert len(chunks) > 0

    @pytest.mark.asyncio
    async def test_chunking_unicode_content(self, embedding_service):
        """Test chunking handles unicode characters."""
        content = "Unicode test: ä½ å¥½ä¸–ç•Œ ðŸŒ CafÃ© rÃ©sumÃ©. " * 30
        chunks = await embedding_service.chunk_document(content, max_chunk_size=1000, overlap=100)

        assert len(chunks) > 0
        for chunk in chunks:
            assert chunk['content_hash']  # Hash should work with unicode

    @pytest.mark.asyncio
    async def test_embedding_generation_max_retries_exceeded(self, embedding_service):
        """Test that max retries raises exception."""
        from openai import RateLimitError

        texts = ["Test text"]

        # Always fail with rate limit error
        embedding_service.client.embeddings.create = AsyncMock(
            side_effect=RateLimitError("Rate limit exceeded", response=Mock(status_code=429), body=None)
        )

        with pytest.raises(RateLimitError):
            await embedding_service.generate_embeddings(texts, max_retries=2)
